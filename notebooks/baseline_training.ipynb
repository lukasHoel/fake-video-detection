{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"baseline_training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575356198001,"user_tz":-60,"elapsed":27824,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}},"id":"B1BOhxh7BEYm","outputId":"0d1d86d8-11f5-4fbe-9736-87289b1a5701","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# Google Colab setup\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"drive/My Drive/adl4cv\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VTsC8dapAyAD","colab":{}},"source":["# ONLY NECESSARY FOR LOCAL EXECUTION (WORKS WITHOUT THIS CELL IN GOOGLE COLAB)\n","# Setup that is necessary for jupyter notebook to find sibling-directories\n","# see: https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n","\n","import os\n","import sys\n","module_path = os.path.abspath(os.path.join('..'))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wa4L43dvAyAr","colab":{}},"source":["# FROM i2dl for nice setup\n","# As usual, a bit of setup\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2\n","\n","# supress cluttering warnings in solutions\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","def rel_error(x, y):\n","  \"\"\" returns relative error \"\"\"\n","  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EGfclJp_AyA7","colab":{}},"source":["# Imports for this notebook\n","\n","from networks.baseline import BaselineModel\n","from training.solver import Solver\n","from training.single_image_dataloader import FaceForensicsImagesDataset, ToTensor\n","from torch.utils import data\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TcKlv4vsAyBE","colab":{}},"source":["data_location = [\"/content/drive/My Drive/FaceForensics_Sequences/original_sequences/youtube/c40/sequences_299x299_5seq@10frames_skip_5_uniform\",\n","                 \"/content/drive/My Drive/FaceForensics_Sequences/manipulated_sequences/Deepfakes/c40/sequences_299x299_5seq@10frames_skip_5_uniform\"]\n","dataset = FaceForensicsImagesDataset(data_location, transform=ToTensor())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575356404462,"user_tz":-60,"elapsed":489,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}},"id":"aJLyrjl2AyBK","outputId":"13a81bee-e597-41ef-ae91-84643b491ab1","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# from: https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n","\n","batch_size = 10\n","validation_split = .2\n","\n","# Creating data indices for training and validation splits:\n","train_indices, val_indices = dataset.get_train_val_lists(1 - validation_split, validation_split)\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)\n","\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n","                                           sampler=train_sampler)\n","validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                                sampler=valid_sampler)\n","\n","print(\"Train samples: {}\".format(len(train_loader)))\n","print(\"Validation samples: {}\".format(len(validation_loader)))\n","\n","#for i, sample in enumerate(train_loader):\n","    \n","    #print(\"count of sequences in this batch: {}\".format(sample[\"images\"][0].shape[0]))\n","    \n","    #sequence = sample[\"images\"][0][0, :, :, :, :]\n","    #labels_for_sequence = sample[\"labels\"]\n","    #print(labels_for_sequence)\n","    \n","    #print(sequence.shape)\n","    #img = sequence[0].numpy()\n","    #img = np.moveaxis(img, 0, -1)  \n","    #plt.imshow(img)\n","    #plt.show()\n","    \n","    \n","    #print(sample[\"images\"][0].shape)\n","    #print(sample[\"labels\"][0].shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train samples: 720\n","Validation samples: 180\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575356674224,"user_tz":-60,"elapsed":259577,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}},"id":"JEDxAVJDAyBX","outputId":"85be0dce-548e-47f2-b9fc-932e114fec83","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Load baseline model\n","model = BaselineModel(model_choice='xception', num_out_classes=2, dropout=0.0)\n","model.train_only_last_layer()\n","\n","print(model)\n","print(\"----------\")\n","print(\"Only the following layers require gradient backpropagation (param.requires_grad)\")\n","for name, param in model.model.named_parameters():\n","    if param.requires_grad:\n","        print(\"param: {} requires_grad: {}\".format(name, param.requires_grad))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth\" to /root/.cache/torch/checkpoints/xception-43020ad28.pth\n","100%|██████████| 87.4M/87.4M [04:17<00:00, 356kB/s]"],"name":"stderr"},{"output_type":"stream","text":["BaselineModel(\n","  (model): Xception(\n","    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace=True)\n","    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace=True)\n","    (block1): Block(\n","      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (rep): Sequential(\n","        (0): SeparableConv2d(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): SeparableConv2d(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      )\n","    )\n","    (block2): Block(\n","      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      )\n","    )\n","    (block3): Block(\n","      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      )\n","    )\n","    (block4): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block5): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block6): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block7): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block8): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block9): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block10): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block11): Block(\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","        (7): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block12): Block(\n","      (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (rep): Sequential(\n","        (0): ReLU()\n","        (1): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): SeparableConv2d(\n","          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n","          (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      )\n","    )\n","    (conv3): SeparableConv2d(\n","      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n","      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU(inplace=True)\n","    (conv4): SeparableConv2d(\n","      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (last_linear): Linear(in_features=2048, out_features=2, bias=True)\n","  )\n",")\n","----------\n","Only the following layers require gradient backpropagation (param.requires_grad)\n","param: last_linear.weight requires_grad: True\n","param: last_linear.bias requires_grad: True\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575360436317,"user_tz":-60,"elapsed":2552348,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}},"id":"QY38vRjuAyBc","outputId":"0ac54d4c-4305-4009-8f20-9a5298fabab8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#configure solver and start training\n","solver = Solver(optim=torch.optim.Adam,\n","                optim_args={ \"lr\": 1e-4,\n","                             \"betas\": (0.9, 0.999),\n","                             \"eps\": 1e-8,\n","                             \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n","                loss_func=torch.nn.CrossEntropyLoss())\n","\n","# Baseline must be trained to get the last classification layer to work correctly, because Xception-net is pretrained on\n","# ImageNet with 1000 class outputs and we only need 2.\n","\n","solver.train(model, train_loader, validation_loader, num_epochs=1, log_nth=1)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["START TRAIN on device: cuda:0\n","[Iteration 1/720] TRAIN loss: 0.6855854988098145\n","[Iteration 2/720] TRAIN loss: 0.6901168823242188\n","[Iteration 3/720] TRAIN loss: 0.6903411746025085\n","[Iteration 4/720] TRAIN loss: 0.7005955576896667\n","[Iteration 5/720] TRAIN loss: 0.7121652960777283\n","[Iteration 6/720] TRAIN loss: 0.7169417142868042\n","[Iteration 7/720] TRAIN loss: 0.7035855054855347\n","[Iteration 8/720] TRAIN loss: 0.6587950587272644\n","[Iteration 9/720] TRAIN loss: 0.6951094269752502\n","[Iteration 10/720] TRAIN loss: 0.6734022498130798\n","[Iteration 11/720] TRAIN loss: 0.6957934498786926\n","[Iteration 12/720] TRAIN loss: 0.6887425184249878\n","[Iteration 13/720] TRAIN loss: 0.6724006533622742\n","[Iteration 14/720] TRAIN loss: 0.6743676662445068\n","[Iteration 15/720] TRAIN loss: 0.6920250654220581\n","[Iteration 16/720] TRAIN loss: 0.6405638456344604\n","[Iteration 17/720] TRAIN loss: 0.6848465204238892\n","[Iteration 18/720] TRAIN loss: 0.6419966220855713\n","[Iteration 19/720] TRAIN loss: 0.7026101350784302\n","[Iteration 20/720] TRAIN loss: 0.650883138179779\n","[Iteration 21/720] TRAIN loss: 0.6387952566146851\n","[Iteration 22/720] TRAIN loss: 0.634869396686554\n","[Iteration 23/720] TRAIN loss: 0.6391239166259766\n","[Iteration 24/720] TRAIN loss: 0.659704327583313\n","[Iteration 25/720] TRAIN loss: 0.6346498727798462\n","[Iteration 26/720] TRAIN loss: 0.685340404510498\n","[Iteration 27/720] TRAIN loss: 0.6486488580703735\n","[Iteration 28/720] TRAIN loss: 0.6287369132041931\n","[Iteration 29/720] TRAIN loss: 0.683660626411438\n","[Iteration 30/720] TRAIN loss: 0.6794573664665222\n","[Iteration 31/720] TRAIN loss: 0.6106910109519958\n","[Iteration 32/720] TRAIN loss: 0.6378287076950073\n","[Iteration 33/720] TRAIN loss: 0.6737419366836548\n","[Iteration 34/720] TRAIN loss: 0.6610606908798218\n","[Iteration 35/720] TRAIN loss: 0.6451724767684937\n","[Iteration 36/720] TRAIN loss: 0.5983808040618896\n","[Iteration 37/720] TRAIN loss: 0.7022031545639038\n","[Iteration 38/720] TRAIN loss: 0.6416178345680237\n","[Iteration 39/720] TRAIN loss: 0.6062873005867004\n","[Iteration 40/720] TRAIN loss: 0.6102897524833679\n","[Iteration 41/720] TRAIN loss: 0.6552445292472839\n","[Iteration 42/720] TRAIN loss: 0.6447914838790894\n","[Iteration 43/720] TRAIN loss: 0.606647789478302\n","[Iteration 44/720] TRAIN loss: 0.6323173642158508\n","[Iteration 45/720] TRAIN loss: 0.6054710745811462\n","[Iteration 46/720] TRAIN loss: 0.6272631287574768\n","[Iteration 47/720] TRAIN loss: 0.6271840333938599\n","[Iteration 48/720] TRAIN loss: 0.6273823380470276\n","[Iteration 49/720] TRAIN loss: 0.5772079229354858\n","[Iteration 50/720] TRAIN loss: 0.590835452079773\n","[Iteration 51/720] TRAIN loss: 0.5925474762916565\n","[Iteration 52/720] TRAIN loss: 0.6223911046981812\n","[Iteration 53/720] TRAIN loss: 0.6215222477912903\n","[Iteration 54/720] TRAIN loss: 0.59356290102005\n","[Iteration 55/720] TRAIN loss: 0.5979464650154114\n","[Iteration 56/720] TRAIN loss: 0.5731479525566101\n","[Iteration 57/720] TRAIN loss: 0.5967208743095398\n","[Iteration 58/720] TRAIN loss: 0.5832695364952087\n","[Iteration 59/720] TRAIN loss: 0.6428195834159851\n","[Iteration 60/720] TRAIN loss: 0.5861901044845581\n","[Iteration 61/720] TRAIN loss: 0.5850142240524292\n","[Iteration 62/720] TRAIN loss: 0.601591169834137\n","[Iteration 63/720] TRAIN loss: 0.6048111915588379\n","[Iteration 64/720] TRAIN loss: 0.5640268325805664\n","[Iteration 65/720] TRAIN loss: 0.5904632210731506\n","[Iteration 66/720] TRAIN loss: 0.5719625353813171\n","[Iteration 67/720] TRAIN loss: 0.5614203810691833\n","[Iteration 68/720] TRAIN loss: 0.6074701547622681\n","[Iteration 69/720] TRAIN loss: 0.5542165040969849\n","[Iteration 70/720] TRAIN loss: 0.577499508857727\n","[Iteration 71/720] TRAIN loss: 0.5844851732254028\n","[Iteration 72/720] TRAIN loss: 0.5683189630508423\n","[Iteration 73/720] TRAIN loss: 0.6005234122276306\n","[Iteration 74/720] TRAIN loss: 0.5550168752670288\n","[Iteration 75/720] TRAIN loss: 0.541204571723938\n","[Iteration 76/720] TRAIN loss: 0.5406454801559448\n","[Iteration 77/720] TRAIN loss: 0.6846123933792114\n","[Iteration 78/720] TRAIN loss: 0.5286145210266113\n","[Iteration 79/720] TRAIN loss: 0.5774878859519958\n","[Iteration 80/720] TRAIN loss: 0.5566393136978149\n","[Iteration 81/720] TRAIN loss: 0.5796352624893188\n","[Iteration 82/720] TRAIN loss: 0.6079254746437073\n","[Iteration 83/720] TRAIN loss: 0.5690099000930786\n","[Iteration 84/720] TRAIN loss: 0.5447447299957275\n","[Iteration 85/720] TRAIN loss: 0.556763768196106\n","[Iteration 86/720] TRAIN loss: 0.5744073987007141\n","[Iteration 87/720] TRAIN loss: 0.5476625561714172\n","[Iteration 88/720] TRAIN loss: 0.546038031578064\n","[Iteration 89/720] TRAIN loss: 0.5683795213699341\n","[Iteration 90/720] TRAIN loss: 0.6404401063919067\n","[Iteration 91/720] TRAIN loss: 0.5402029156684875\n","[Iteration 92/720] TRAIN loss: 0.5840057134628296\n","[Iteration 93/720] TRAIN loss: 0.6156829595565796\n","[Iteration 94/720] TRAIN loss: 0.5501161813735962\n","[Iteration 95/720] TRAIN loss: 0.4769815504550934\n","[Iteration 96/720] TRAIN loss: 0.628538191318512\n","[Iteration 97/720] TRAIN loss: 0.5838597416877747\n","[Iteration 98/720] TRAIN loss: 0.5538936853408813\n","[Iteration 99/720] TRAIN loss: 0.5130671262741089\n","[Iteration 100/720] TRAIN loss: 0.5561540722846985\n","[Iteration 101/720] TRAIN loss: 0.5178059339523315\n","[Iteration 102/720] TRAIN loss: 0.5211879014968872\n","[Iteration 103/720] TRAIN loss: 0.470817893743515\n","[Iteration 104/720] TRAIN loss: 0.527346670627594\n","[Iteration 105/720] TRAIN loss: 0.534675657749176\n","[Iteration 106/720] TRAIN loss: 0.5391793847084045\n","[Iteration 107/720] TRAIN loss: 0.5100747346878052\n","[Iteration 108/720] TRAIN loss: 0.5566681623458862\n","[Iteration 109/720] TRAIN loss: 0.5113956332206726\n","[Iteration 110/720] TRAIN loss: 0.48082226514816284\n","[Iteration 111/720] TRAIN loss: 0.5415769815444946\n","[Iteration 112/720] TRAIN loss: 0.6416835188865662\n","[Iteration 113/720] TRAIN loss: 0.5015778541564941\n","[Iteration 114/720] TRAIN loss: 0.4902442991733551\n","[Iteration 115/720] TRAIN loss: 0.501166045665741\n","[Iteration 116/720] TRAIN loss: 0.5199462175369263\n","[Iteration 117/720] TRAIN loss: 0.49082937836647034\n","[Iteration 118/720] TRAIN loss: 0.5646796822547913\n","[Iteration 119/720] TRAIN loss: 0.5421124696731567\n","[Iteration 120/720] TRAIN loss: 0.5251263380050659\n","[Iteration 121/720] TRAIN loss: 0.5675930976867676\n","[Iteration 122/720] TRAIN loss: 0.49399423599243164\n","[Iteration 123/720] TRAIN loss: 0.6025445461273193\n","[Iteration 124/720] TRAIN loss: 0.5077077150344849\n","[Iteration 125/720] TRAIN loss: 0.5646845698356628\n","[Iteration 126/720] TRAIN loss: 0.5076558589935303\n","[Iteration 127/720] TRAIN loss: 0.5227077603340149\n","[Iteration 128/720] TRAIN loss: 0.4872382581233978\n","[Iteration 129/720] TRAIN loss: 0.4975128769874573\n","[Iteration 130/720] TRAIN loss: 0.5719135999679565\n","[Iteration 131/720] TRAIN loss: 0.48512783646583557\n","[Iteration 132/720] TRAIN loss: 0.4608529508113861\n","[Iteration 133/720] TRAIN loss: 0.47894716262817383\n","[Iteration 134/720] TRAIN loss: 0.5267449617385864\n","[Iteration 135/720] TRAIN loss: 0.4892292618751526\n","[Iteration 136/720] TRAIN loss: 0.5901585221290588\n","[Iteration 137/720] TRAIN loss: 0.4672325551509857\n","[Iteration 138/720] TRAIN loss: 0.42994314432144165\n","[Iteration 139/720] TRAIN loss: 0.4506080746650696\n","[Iteration 140/720] TRAIN loss: 0.5080726146697998\n","[Iteration 141/720] TRAIN loss: 0.479743093252182\n","[Iteration 142/720] TRAIN loss: 0.5403053164482117\n","[Iteration 143/720] TRAIN loss: 0.49466294050216675\n","[Iteration 144/720] TRAIN loss: 0.46863141655921936\n","[Iteration 145/720] TRAIN loss: 0.5397615432739258\n","[Iteration 146/720] TRAIN loss: 0.5498599410057068\n","[Iteration 147/720] TRAIN loss: 0.5211540460586548\n","[Iteration 148/720] TRAIN loss: 0.5072871446609497\n","[Iteration 149/720] TRAIN loss: 0.5238681435585022\n","[Iteration 150/720] TRAIN loss: 0.4494245648384094\n","[Iteration 151/720] TRAIN loss: 0.44864416122436523\n","[Iteration 152/720] TRAIN loss: 0.42366284132003784\n","[Iteration 153/720] TRAIN loss: 0.45519208908081055\n","[Iteration 154/720] TRAIN loss: 0.5917500257492065\n","[Iteration 155/720] TRAIN loss: 0.6444442868232727\n","[Iteration 156/720] TRAIN loss: 0.4099828600883484\n","[Iteration 157/720] TRAIN loss: 0.4423304498195648\n","[Iteration 158/720] TRAIN loss: 0.5309394598007202\n","[Iteration 159/720] TRAIN loss: 0.46622180938720703\n","[Iteration 160/720] TRAIN loss: 0.45364856719970703\n","[Iteration 161/720] TRAIN loss: 0.44187673926353455\n","[Iteration 162/720] TRAIN loss: 0.5397857427597046\n","[Iteration 163/720] TRAIN loss: 0.4355173707008362\n","[Iteration 164/720] TRAIN loss: 0.5525708198547363\n","[Iteration 165/720] TRAIN loss: 0.5103052854537964\n","[Iteration 166/720] TRAIN loss: 0.5402172803878784\n","[Iteration 167/720] TRAIN loss: 0.6440166234970093\n","[Iteration 168/720] TRAIN loss: 0.4730004370212555\n","[Iteration 169/720] TRAIN loss: 0.5199175477027893\n","[Iteration 170/720] TRAIN loss: 0.5565963983535767\n","[Iteration 171/720] TRAIN loss: 0.46016016602516174\n","[Iteration 172/720] TRAIN loss: 0.4453653395175934\n","[Iteration 173/720] TRAIN loss: 0.4689106047153473\n","[Iteration 174/720] TRAIN loss: 0.42122501134872437\n","[Iteration 175/720] TRAIN loss: 0.5200985074043274\n","[Iteration 176/720] TRAIN loss: 0.4916589856147766\n","[Iteration 177/720] TRAIN loss: 0.4793291687965393\n","[Iteration 178/720] TRAIN loss: 0.423911988735199\n","[Iteration 179/720] TRAIN loss: 0.624686598777771\n","[Iteration 180/720] TRAIN loss: 0.41062989830970764\n","[Iteration 181/720] TRAIN loss: 0.4756244122982025\n","[Iteration 182/720] TRAIN loss: 0.5257004499435425\n","[Iteration 183/720] TRAIN loss: 0.45980969071388245\n","[Iteration 184/720] TRAIN loss: 0.37733328342437744\n","[Iteration 185/720] TRAIN loss: 0.46590954065322876\n","[Iteration 186/720] TRAIN loss: 0.38489454984664917\n","[Iteration 187/720] TRAIN loss: 0.48575249314308167\n","[Iteration 188/720] TRAIN loss: 0.4914396405220032\n","[Iteration 189/720] TRAIN loss: 0.4745250642299652\n","[Iteration 190/720] TRAIN loss: 0.4412744641304016\n","[Iteration 191/720] TRAIN loss: 0.3778994679450989\n","[Iteration 192/720] TRAIN loss: 0.551788330078125\n","[Iteration 193/720] TRAIN loss: 0.4604848027229309\n","[Iteration 194/720] TRAIN loss: 0.38641291856765747\n","[Iteration 195/720] TRAIN loss: 0.4568202495574951\n","[Iteration 196/720] TRAIN loss: 0.45609110593795776\n","[Iteration 197/720] TRAIN loss: 0.4288231432437897\n","[Iteration 198/720] TRAIN loss: 0.44196033477783203\n","[Iteration 199/720] TRAIN loss: 0.3963228166103363\n","[Iteration 200/720] TRAIN loss: 0.45999807119369507\n","[Iteration 201/720] TRAIN loss: 0.41388648748397827\n","[Iteration 202/720] TRAIN loss: 0.4465872645378113\n","[Iteration 203/720] TRAIN loss: 0.44590240716934204\n","[Iteration 204/720] TRAIN loss: 0.38965362310409546\n","[Iteration 205/720] TRAIN loss: 0.47004932165145874\n","[Iteration 206/720] TRAIN loss: 0.3889586925506592\n","[Iteration 207/720] TRAIN loss: 0.45686936378479004\n","[Iteration 208/720] TRAIN loss: 0.4150627553462982\n","[Iteration 209/720] TRAIN loss: 0.4600711464881897\n","[Iteration 210/720] TRAIN loss: 0.46268147230148315\n","[Iteration 211/720] TRAIN loss: 0.38013261556625366\n","[Iteration 212/720] TRAIN loss: 0.4292904734611511\n","[Iteration 213/720] TRAIN loss: 0.4388677179813385\n","[Iteration 214/720] TRAIN loss: 0.498500257730484\n","[Iteration 215/720] TRAIN loss: 0.4680544435977936\n","[Iteration 216/720] TRAIN loss: 0.3591929078102112\n","[Iteration 217/720] TRAIN loss: 0.4097740650177002\n","[Iteration 218/720] TRAIN loss: 0.39100125432014465\n","[Iteration 219/720] TRAIN loss: 0.3459806442260742\n","[Iteration 220/720] TRAIN loss: 0.4559013843536377\n","[Iteration 221/720] TRAIN loss: 0.41710907220840454\n","[Iteration 222/720] TRAIN loss: 0.503312349319458\n","[Iteration 223/720] TRAIN loss: 0.39215564727783203\n","[Iteration 224/720] TRAIN loss: 0.4263485074043274\n","[Iteration 225/720] TRAIN loss: 0.43684086203575134\n","[Iteration 226/720] TRAIN loss: 0.46589088439941406\n","[Iteration 227/720] TRAIN loss: 0.4764845371246338\n","[Iteration 228/720] TRAIN loss: 0.36545535922050476\n","[Iteration 229/720] TRAIN loss: 0.3913297653198242\n","[Iteration 230/720] TRAIN loss: 0.4383316934108734\n","[Iteration 231/720] TRAIN loss: 0.38725143671035767\n","[Iteration 232/720] TRAIN loss: 0.39432674646377563\n","[Iteration 233/720] TRAIN loss: 0.7976099848747253\n","[Iteration 234/720] TRAIN loss: 0.3872922360897064\n","[Iteration 235/720] TRAIN loss: 0.3773661255836487\n","[Iteration 236/720] TRAIN loss: 0.35444027185440063\n","[Iteration 237/720] TRAIN loss: 0.5510807633399963\n","[Iteration 238/720] TRAIN loss: 0.34410157799720764\n","[Iteration 239/720] TRAIN loss: 0.42414504289627075\n","[Iteration 240/720] TRAIN loss: 0.5050176382064819\n","[Iteration 241/720] TRAIN loss: 0.453483521938324\n","[Iteration 242/720] TRAIN loss: 0.561134934425354\n","[Iteration 243/720] TRAIN loss: 0.378257691860199\n","[Iteration 244/720] TRAIN loss: 0.421121746301651\n","[Iteration 245/720] TRAIN loss: 0.4923873841762543\n","[Iteration 246/720] TRAIN loss: 0.34206312894821167\n","[Iteration 247/720] TRAIN loss: 0.3931978940963745\n","[Iteration 248/720] TRAIN loss: 0.32530567049980164\n","[Iteration 249/720] TRAIN loss: 0.382866233587265\n","[Iteration 250/720] TRAIN loss: 0.376528799533844\n","[Iteration 251/720] TRAIN loss: 0.4997434616088867\n","[Iteration 252/720] TRAIN loss: 0.3582145869731903\n","[Iteration 253/720] TRAIN loss: 0.41999325156211853\n","[Iteration 254/720] TRAIN loss: 0.40758824348449707\n","[Iteration 255/720] TRAIN loss: 0.30807411670684814\n","[Iteration 256/720] TRAIN loss: 0.33517104387283325\n","[Iteration 257/720] TRAIN loss: 0.5685685873031616\n","[Iteration 258/720] TRAIN loss: 0.35856810212135315\n","[Iteration 259/720] TRAIN loss: 0.42320409417152405\n","[Iteration 260/720] TRAIN loss: 0.37129124999046326\n","[Iteration 261/720] TRAIN loss: 0.5163143873214722\n","[Iteration 262/720] TRAIN loss: 0.34521958231925964\n","[Iteration 263/720] TRAIN loss: 0.3222902715206146\n","[Iteration 264/720] TRAIN loss: 0.40805068612098694\n","[Iteration 265/720] TRAIN loss: 0.4355246126651764\n","[Iteration 266/720] TRAIN loss: 0.42730993032455444\n","[Iteration 267/720] TRAIN loss: 0.41032272577285767\n","[Iteration 268/720] TRAIN loss: 0.3785979747772217\n","[Iteration 269/720] TRAIN loss: 0.39580124616622925\n","[Iteration 270/720] TRAIN loss: 0.5090693235397339\n","[Iteration 271/720] TRAIN loss: 0.3959871232509613\n","[Iteration 272/720] TRAIN loss: 0.4921848773956299\n","[Iteration 273/720] TRAIN loss: 0.41386812925338745\n","[Iteration 274/720] TRAIN loss: 0.45851173996925354\n","[Iteration 275/720] TRAIN loss: 0.3455324172973633\n","[Iteration 276/720] TRAIN loss: 0.4884422719478607\n","[Iteration 277/720] TRAIN loss: 0.41574063897132874\n","[Iteration 278/720] TRAIN loss: 0.3742436170578003\n","[Iteration 279/720] TRAIN loss: 0.4168727397918701\n","[Iteration 280/720] TRAIN loss: 0.6161144375801086\n","[Iteration 281/720] TRAIN loss: 0.43713387846946716\n","[Iteration 282/720] TRAIN loss: 0.41840696334838867\n","[Iteration 283/720] TRAIN loss: 0.3537921905517578\n","[Iteration 284/720] TRAIN loss: 0.28882288932800293\n","[Iteration 285/720] TRAIN loss: 0.534190833568573\n","[Iteration 286/720] TRAIN loss: 0.36307671666145325\n","[Iteration 287/720] TRAIN loss: 0.4331817030906677\n","[Iteration 288/720] TRAIN loss: 0.35954540967941284\n","[Iteration 289/720] TRAIN loss: 0.46773824095726013\n","[Iteration 290/720] TRAIN loss: 0.3175325095653534\n","[Iteration 291/720] TRAIN loss: 0.36760884523391724\n","[Iteration 292/720] TRAIN loss: 0.3954898715019226\n","[Iteration 293/720] TRAIN loss: 0.3630136549472809\n","[Iteration 294/720] TRAIN loss: 0.6100456714630127\n","[Iteration 295/720] TRAIN loss: 0.39820772409439087\n","[Iteration 296/720] TRAIN loss: 0.4349183142185211\n","[Iteration 297/720] TRAIN loss: 0.3839629292488098\n","[Iteration 298/720] TRAIN loss: 0.3442557752132416\n","[Iteration 299/720] TRAIN loss: 0.30455324053764343\n","[Iteration 300/720] TRAIN loss: 0.3542633652687073\n","[Iteration 301/720] TRAIN loss: 0.29869312047958374\n","[Iteration 302/720] TRAIN loss: 0.36701875925064087\n","[Iteration 303/720] TRAIN loss: 0.47730177640914917\n","[Iteration 304/720] TRAIN loss: 0.4972662925720215\n","[Iteration 305/720] TRAIN loss: 0.37678566575050354\n","[Iteration 306/720] TRAIN loss: 0.36733493208885193\n","[Iteration 307/720] TRAIN loss: 0.4205717444419861\n","[Iteration 308/720] TRAIN loss: 0.3718682527542114\n","[Iteration 309/720] TRAIN loss: 0.3504372537136078\n","[Iteration 310/720] TRAIN loss: 0.5767462849617004\n","[Iteration 311/720] TRAIN loss: 0.3996291756629944\n","[Iteration 312/720] TRAIN loss: 0.3955177664756775\n","[Iteration 313/720] TRAIN loss: 0.39054760336875916\n","[Iteration 314/720] TRAIN loss: 0.5503548383712769\n","[Iteration 315/720] TRAIN loss: 0.32898861169815063\n","[Iteration 316/720] TRAIN loss: 0.3164382576942444\n","[Iteration 317/720] TRAIN loss: 0.3331691324710846\n","[Iteration 318/720] TRAIN loss: 0.23229441046714783\n","[Iteration 319/720] TRAIN loss: 0.3052375316619873\n","[Iteration 320/720] TRAIN loss: 0.3435102105140686\n","[Iteration 321/720] TRAIN loss: 0.451542466878891\n","[Iteration 322/720] TRAIN loss: 0.35933050513267517\n","[Iteration 323/720] TRAIN loss: 0.37056106328964233\n","[Iteration 324/720] TRAIN loss: 0.3983080983161926\n","[Iteration 325/720] TRAIN loss: 0.36047935485839844\n","[Iteration 326/720] TRAIN loss: 0.2756751477718353\n","[Iteration 327/720] TRAIN loss: 0.3586903214454651\n","[Iteration 328/720] TRAIN loss: 0.3626764416694641\n","[Iteration 329/720] TRAIN loss: 0.3196827471256256\n","[Iteration 330/720] TRAIN loss: 0.2751823365688324\n","[Iteration 331/720] TRAIN loss: 0.3817811608314514\n","[Iteration 332/720] TRAIN loss: 0.5348499417304993\n","[Iteration 333/720] TRAIN loss: 0.3953842520713806\n","[Iteration 334/720] TRAIN loss: 0.4528059959411621\n","[Iteration 335/720] TRAIN loss: 0.4114498496055603\n","[Iteration 336/720] TRAIN loss: 0.3726215362548828\n","[Iteration 337/720] TRAIN loss: 0.5065166354179382\n","[Iteration 338/720] TRAIN loss: 0.38530999422073364\n","[Iteration 339/720] TRAIN loss: 0.4999043047428131\n","[Iteration 340/720] TRAIN loss: 0.4889184832572937\n","[Iteration 341/720] TRAIN loss: 0.35387447476387024\n","[Iteration 342/720] TRAIN loss: 0.2997400760650635\n","[Iteration 343/720] TRAIN loss: 0.2995181679725647\n","[Iteration 344/720] TRAIN loss: 0.3729814887046814\n","[Iteration 345/720] TRAIN loss: 0.45071664452552795\n","[Iteration 346/720] TRAIN loss: 0.3838624358177185\n","[Iteration 347/720] TRAIN loss: 0.33523428440093994\n","[Iteration 348/720] TRAIN loss: 0.2963470220565796\n","[Iteration 349/720] TRAIN loss: 0.3801106810569763\n","[Iteration 350/720] TRAIN loss: 0.38627317547798157\n","[Iteration 351/720] TRAIN loss: 0.31529635190963745\n","[Iteration 352/720] TRAIN loss: 0.3324243724346161\n","[Iteration 353/720] TRAIN loss: 0.2532062530517578\n","[Iteration 354/720] TRAIN loss: 0.44617128372192383\n","[Iteration 355/720] TRAIN loss: 0.44630247354507446\n","[Iteration 356/720] TRAIN loss: 0.3104235529899597\n","[Iteration 357/720] TRAIN loss: 0.30090564489364624\n","[Iteration 358/720] TRAIN loss: 0.4678281843662262\n","[Iteration 359/720] TRAIN loss: 0.2634739279747009\n","[Iteration 360/720] TRAIN loss: 0.33431801199913025\n","[Iteration 361/720] TRAIN loss: 0.3078053593635559\n","[Iteration 362/720] TRAIN loss: 0.39189544320106506\n","[Iteration 363/720] TRAIN loss: 0.330894410610199\n","[Iteration 364/720] TRAIN loss: 0.32933318614959717\n","[Iteration 365/720] TRAIN loss: 0.4319940507411957\n","[Iteration 366/720] TRAIN loss: 0.364576518535614\n","[Iteration 367/720] TRAIN loss: 0.30675405263900757\n","[Iteration 368/720] TRAIN loss: 0.24852681159973145\n","[Iteration 369/720] TRAIN loss: 0.2756277322769165\n","[Iteration 370/720] TRAIN loss: 0.4010019302368164\n","[Iteration 371/720] TRAIN loss: 0.2594500482082367\n","[Iteration 372/720] TRAIN loss: 0.26956483721733093\n","[Iteration 373/720] TRAIN loss: 0.325015127658844\n","[Iteration 374/720] TRAIN loss: 0.29892295598983765\n","[Iteration 375/720] TRAIN loss: 0.34900516271591187\n","[Iteration 376/720] TRAIN loss: 0.28501689434051514\n","[Iteration 377/720] TRAIN loss: 0.3400033116340637\n","[Iteration 378/720] TRAIN loss: 0.36288708448410034\n","[Iteration 379/720] TRAIN loss: 0.4602340757846832\n","[Iteration 380/720] TRAIN loss: 0.263335645198822\n","[Iteration 381/720] TRAIN loss: 0.4149874150753021\n","[Iteration 382/720] TRAIN loss: 0.39671069383621216\n","[Iteration 383/720] TRAIN loss: 0.27388525009155273\n","[Iteration 384/720] TRAIN loss: 0.35616201162338257\n","[Iteration 385/720] TRAIN loss: 0.3889370560646057\n","[Iteration 386/720] TRAIN loss: 0.47002094984054565\n","[Iteration 387/720] TRAIN loss: 0.3618203103542328\n","[Iteration 388/720] TRAIN loss: 0.39133888483047485\n","[Iteration 389/720] TRAIN loss: 0.28418970108032227\n","[Iteration 390/720] TRAIN loss: 0.40178561210632324\n","[Iteration 391/720] TRAIN loss: 0.370439350605011\n","[Iteration 392/720] TRAIN loss: 0.43737760186195374\n","[Iteration 393/720] TRAIN loss: 0.3486979603767395\n","[Iteration 394/720] TRAIN loss: 0.32341209053993225\n","[Iteration 395/720] TRAIN loss: 0.5470958948135376\n","[Iteration 396/720] TRAIN loss: 0.33175283670425415\n","[Iteration 397/720] TRAIN loss: 0.3678961396217346\n","[Iteration 398/720] TRAIN loss: 0.24429282546043396\n","[Iteration 399/720] TRAIN loss: 0.36301136016845703\n","[Iteration 400/720] TRAIN loss: 0.3590901494026184\n","[Iteration 401/720] TRAIN loss: 0.38375112414360046\n","[Iteration 402/720] TRAIN loss: 0.34299004077911377\n","[Iteration 403/720] TRAIN loss: 0.3038727343082428\n","[Iteration 404/720] TRAIN loss: 0.25970330834388733\n","[Iteration 405/720] TRAIN loss: 0.3391067385673523\n","[Iteration 406/720] TRAIN loss: 0.4006631374359131\n","[Iteration 407/720] TRAIN loss: 0.3543514609336853\n","[Iteration 408/720] TRAIN loss: 0.25985556840896606\n","[Iteration 409/720] TRAIN loss: 0.2464611530303955\n","[Iteration 410/720] TRAIN loss: 0.2646287977695465\n","[Iteration 411/720] TRAIN loss: 0.34936273097991943\n","[Iteration 412/720] TRAIN loss: 0.339616596698761\n","[Iteration 413/720] TRAIN loss: 0.3523571491241455\n","[Iteration 414/720] TRAIN loss: 0.317362904548645\n","[Iteration 415/720] TRAIN loss: 0.23393526673316956\n","[Iteration 416/720] TRAIN loss: 0.4163669943809509\n","[Iteration 417/720] TRAIN loss: 0.40148472785949707\n","[Iteration 418/720] TRAIN loss: 0.33635804057121277\n","[Iteration 419/720] TRAIN loss: 0.5726991295814514\n","[Iteration 420/720] TRAIN loss: 0.32597023248672485\n","[Iteration 421/720] TRAIN loss: 0.42034825682640076\n","[Iteration 422/720] TRAIN loss: 0.29731616377830505\n","[Iteration 423/720] TRAIN loss: 0.3645050525665283\n","[Iteration 424/720] TRAIN loss: 0.48379620909690857\n","[Iteration 425/720] TRAIN loss: 0.3246307671070099\n","[Iteration 426/720] TRAIN loss: 0.33655399084091187\n","[Iteration 427/720] TRAIN loss: 0.1973676085472107\n","[Iteration 428/720] TRAIN loss: 0.4049604535102844\n","[Iteration 429/720] TRAIN loss: 0.30768853425979614\n","[Iteration 430/720] TRAIN loss: 0.3595139682292938\n","[Iteration 431/720] TRAIN loss: 0.32620370388031006\n","[Iteration 432/720] TRAIN loss: 0.2759229242801666\n","[Iteration 433/720] TRAIN loss: 0.30500930547714233\n","[Iteration 434/720] TRAIN loss: 0.501727819442749\n","[Iteration 435/720] TRAIN loss: 0.3792154788970947\n","[Iteration 436/720] TRAIN loss: 0.3642769157886505\n","[Iteration 437/720] TRAIN loss: 0.2774384617805481\n","[Iteration 438/720] TRAIN loss: 0.5622853636741638\n","[Iteration 439/720] TRAIN loss: 0.4114789366722107\n","[Iteration 440/720] TRAIN loss: 0.23174810409545898\n","[Iteration 441/720] TRAIN loss: 0.3912714719772339\n","[Iteration 442/720] TRAIN loss: 0.29239073395729065\n","[Iteration 443/720] TRAIN loss: 0.37249207496643066\n","[Iteration 444/720] TRAIN loss: 0.3301306664943695\n","[Iteration 445/720] TRAIN loss: 0.25796887278556824\n","[Iteration 446/720] TRAIN loss: 0.46611231565475464\n","[Iteration 447/720] TRAIN loss: 0.2859651446342468\n","[Iteration 448/720] TRAIN loss: 0.2971000075340271\n","[Iteration 449/720] TRAIN loss: 0.29147109389305115\n","[Iteration 450/720] TRAIN loss: 0.2980230450630188\n","[Iteration 451/720] TRAIN loss: 0.3620204031467438\n","[Iteration 452/720] TRAIN loss: 0.3667925298213959\n","[Iteration 453/720] TRAIN loss: 0.31680208444595337\n","[Iteration 454/720] TRAIN loss: 0.44110241532325745\n","[Iteration 455/720] TRAIN loss: 0.19041338562965393\n","[Iteration 456/720] TRAIN loss: 0.4127984046936035\n","[Iteration 457/720] TRAIN loss: 0.38181906938552856\n","[Iteration 458/720] TRAIN loss: 0.4411318898200989\n","[Iteration 459/720] TRAIN loss: 0.32673242688179016\n","[Iteration 460/720] TRAIN loss: 0.24904164671897888\n","[Iteration 461/720] TRAIN loss: 0.40796613693237305\n","[Iteration 462/720] TRAIN loss: 0.33115798234939575\n","[Iteration 463/720] TRAIN loss: 0.3174840807914734\n","[Iteration 464/720] TRAIN loss: 0.23619484901428223\n","[Iteration 465/720] TRAIN loss: 0.21177320182323456\n","[Iteration 466/720] TRAIN loss: 0.4407053589820862\n","[Iteration 467/720] TRAIN loss: 0.3951107859611511\n","[Iteration 468/720] TRAIN loss: 0.42123478651046753\n","[Iteration 469/720] TRAIN loss: 0.22478985786437988\n","[Iteration 470/720] TRAIN loss: 0.28725045919418335\n","[Iteration 471/720] TRAIN loss: 0.3255313038825989\n","[Iteration 472/720] TRAIN loss: 0.3685864508152008\n","[Iteration 473/720] TRAIN loss: 0.2989300489425659\n","[Iteration 474/720] TRAIN loss: 0.2885713577270508\n","[Iteration 475/720] TRAIN loss: 0.2343885451555252\n","[Iteration 476/720] TRAIN loss: 0.47763872146606445\n","[Iteration 477/720] TRAIN loss: 0.2855042815208435\n","[Iteration 478/720] TRAIN loss: 0.3171573281288147\n","[Iteration 479/720] TRAIN loss: 0.3615623116493225\n","[Iteration 480/720] TRAIN loss: 0.33578887581825256\n","[Iteration 481/720] TRAIN loss: 0.2981055974960327\n","[Iteration 482/720] TRAIN loss: 0.2963838279247284\n","[Iteration 483/720] TRAIN loss: 0.26100823283195496\n","[Iteration 484/720] TRAIN loss: 0.36278823018074036\n","[Iteration 485/720] TRAIN loss: 0.2868194878101349\n","[Iteration 486/720] TRAIN loss: 0.2612319588661194\n","[Iteration 487/720] TRAIN loss: 0.5253863334655762\n","[Iteration 488/720] TRAIN loss: 0.2584645748138428\n","[Iteration 489/720] TRAIN loss: 0.3819076418876648\n","[Iteration 490/720] TRAIN loss: 0.296735018491745\n","[Iteration 491/720] TRAIN loss: 0.3965868651866913\n","[Iteration 492/720] TRAIN loss: 0.3304941654205322\n","[Iteration 493/720] TRAIN loss: 0.3042791485786438\n","[Iteration 494/720] TRAIN loss: 0.23321127891540527\n","[Iteration 495/720] TRAIN loss: 0.292591392993927\n","[Iteration 496/720] TRAIN loss: 0.3016282021999359\n","[Iteration 497/720] TRAIN loss: 0.23672516644001007\n","[Iteration 498/720] TRAIN loss: 0.33198282122612\n","[Iteration 499/720] TRAIN loss: 0.33412081003189087\n","[Iteration 500/720] TRAIN loss: 0.31430500745773315\n","[Iteration 501/720] TRAIN loss: 0.3703416585922241\n","[Iteration 502/720] TRAIN loss: 0.39292797446250916\n","[Iteration 503/720] TRAIN loss: 0.27389100193977356\n","[Iteration 504/720] TRAIN loss: 0.21478311717510223\n","[Iteration 505/720] TRAIN loss: 0.31036776304244995\n","[Iteration 506/720] TRAIN loss: 0.3026524484157562\n","[Iteration 507/720] TRAIN loss: 0.20990531146526337\n","[Iteration 508/720] TRAIN loss: 0.39592844247817993\n","[Iteration 509/720] TRAIN loss: 0.2913425862789154\n","[Iteration 510/720] TRAIN loss: 0.22817841172218323\n","[Iteration 511/720] TRAIN loss: 0.2995243966579437\n","[Iteration 512/720] TRAIN loss: 0.3757030963897705\n","[Iteration 513/720] TRAIN loss: 0.29694563150405884\n","[Iteration 514/720] TRAIN loss: 0.27851635217666626\n","[Iteration 515/720] TRAIN loss: 0.24276785552501678\n","[Iteration 516/720] TRAIN loss: 0.4818526804447174\n","[Iteration 517/720] TRAIN loss: 0.30534034967422485\n","[Iteration 518/720] TRAIN loss: 0.25912994146347046\n","[Iteration 519/720] TRAIN loss: 0.2049073874950409\n","[Iteration 520/720] TRAIN loss: 0.3960895538330078\n","[Iteration 521/720] TRAIN loss: 0.3053404986858368\n","[Iteration 522/720] TRAIN loss: 0.23523397743701935\n","[Iteration 523/720] TRAIN loss: 0.328885555267334\n","[Iteration 524/720] TRAIN loss: 0.20940876007080078\n","[Iteration 525/720] TRAIN loss: 0.28638261556625366\n","[Iteration 526/720] TRAIN loss: 0.26576095819473267\n","[Iteration 527/720] TRAIN loss: 0.4089584946632385\n","[Iteration 528/720] TRAIN loss: 0.21852704882621765\n","[Iteration 529/720] TRAIN loss: 0.30843910574913025\n","[Iteration 530/720] TRAIN loss: 0.19270846247673035\n","[Iteration 531/720] TRAIN loss: 0.4064338207244873\n","[Iteration 532/720] TRAIN loss: 0.3138524293899536\n","[Iteration 533/720] TRAIN loss: 0.34058141708374023\n","[Iteration 534/720] TRAIN loss: 0.28671494126319885\n","[Iteration 535/720] TRAIN loss: 0.36532536149024963\n","[Iteration 536/720] TRAIN loss: 0.31366926431655884\n","[Iteration 537/720] TRAIN loss: 0.1956915706396103\n","[Iteration 538/720] TRAIN loss: 0.2419973909854889\n","[Iteration 539/720] TRAIN loss: 0.32734325528144836\n","[Iteration 540/720] TRAIN loss: 0.5156136155128479\n","[Iteration 541/720] TRAIN loss: 0.4574020504951477\n","[Iteration 542/720] TRAIN loss: 0.18164533376693726\n","[Iteration 543/720] TRAIN loss: 0.22149638831615448\n","[Iteration 544/720] TRAIN loss: 0.4330503046512604\n","[Iteration 545/720] TRAIN loss: 0.35179129242897034\n","[Iteration 546/720] TRAIN loss: 0.2507534623146057\n","[Iteration 547/720] TRAIN loss: 0.23921695351600647\n","[Iteration 548/720] TRAIN loss: 0.475424587726593\n","[Iteration 549/720] TRAIN loss: 0.3023926317691803\n","[Iteration 550/720] TRAIN loss: 0.2944519519805908\n","[Iteration 551/720] TRAIN loss: 0.35686177015304565\n","[Iteration 552/720] TRAIN loss: 0.20252609252929688\n","[Iteration 553/720] TRAIN loss: 0.3177056908607483\n","[Iteration 554/720] TRAIN loss: 0.2349512130022049\n","[Iteration 555/720] TRAIN loss: 0.20666351914405823\n","[Iteration 556/720] TRAIN loss: 0.3285951018333435\n","[Iteration 557/720] TRAIN loss: 0.2642971873283386\n","[Iteration 558/720] TRAIN loss: 0.32718709111213684\n","[Iteration 559/720] TRAIN loss: 0.27060240507125854\n","[Iteration 560/720] TRAIN loss: 0.3033280372619629\n","[Iteration 561/720] TRAIN loss: 0.2498045712709427\n","[Iteration 562/720] TRAIN loss: 0.5765928030014038\n","[Iteration 563/720] TRAIN loss: 0.28458359837532043\n","[Iteration 564/720] TRAIN loss: 0.25279340147972107\n","[Iteration 565/720] TRAIN loss: 0.2976125478744507\n","[Iteration 566/720] TRAIN loss: 0.28427860140800476\n","[Iteration 567/720] TRAIN loss: 0.28976884484291077\n","[Iteration 568/720] TRAIN loss: 0.34404271841049194\n","[Iteration 569/720] TRAIN loss: 0.3065590262413025\n","[Iteration 570/720] TRAIN loss: 0.2062247097492218\n","[Iteration 571/720] TRAIN loss: 0.31521180272102356\n","[Iteration 572/720] TRAIN loss: 0.5206948518753052\n","[Iteration 573/720] TRAIN loss: 0.4243009090423584\n","[Iteration 574/720] TRAIN loss: 0.21342682838439941\n","[Iteration 575/720] TRAIN loss: 0.28743234276771545\n","[Iteration 576/720] TRAIN loss: 0.2730722725391388\n","[Iteration 577/720] TRAIN loss: 0.3668183386325836\n","[Iteration 578/720] TRAIN loss: 0.31883662939071655\n","[Iteration 579/720] TRAIN loss: 0.35921981930732727\n","[Iteration 580/720] TRAIN loss: 0.19418743252754211\n","[Iteration 581/720] TRAIN loss: 0.5509952306747437\n","[Iteration 582/720] TRAIN loss: 0.3529318869113922\n","[Iteration 583/720] TRAIN loss: 0.2258463352918625\n","[Iteration 584/720] TRAIN loss: 0.36243951320648193\n","[Iteration 585/720] TRAIN loss: 0.3341386914253235\n","[Iteration 586/720] TRAIN loss: 0.28233009576797485\n","[Iteration 587/720] TRAIN loss: 0.24102525413036346\n","[Iteration 588/720] TRAIN loss: 0.28485217690467834\n","[Iteration 589/720] TRAIN loss: 0.30244770646095276\n","[Iteration 590/720] TRAIN loss: 0.5182777047157288\n","[Iteration 591/720] TRAIN loss: 0.2803483307361603\n","[Iteration 592/720] TRAIN loss: 0.23438672721385956\n","[Iteration 593/720] TRAIN loss: 0.38517969846725464\n","[Iteration 594/720] TRAIN loss: 0.4320697784423828\n","[Iteration 595/720] TRAIN loss: 0.5060073733329773\n","[Iteration 596/720] TRAIN loss: 0.5940014123916626\n","[Iteration 597/720] TRAIN loss: 0.20601598918437958\n","[Iteration 598/720] TRAIN loss: 0.18818597495555878\n","[Iteration 599/720] TRAIN loss: 0.22251896560192108\n","[Iteration 600/720] TRAIN loss: 0.33546167612075806\n","[Iteration 601/720] TRAIN loss: 0.34140917658805847\n","[Iteration 602/720] TRAIN loss: 0.27912822365760803\n","[Iteration 603/720] TRAIN loss: 0.32715854048728943\n","[Iteration 604/720] TRAIN loss: 0.33385640382766724\n","[Iteration 605/720] TRAIN loss: 0.6175834536552429\n","[Iteration 606/720] TRAIN loss: 0.5799369812011719\n","[Iteration 607/720] TRAIN loss: 0.2381984442472458\n","[Iteration 608/720] TRAIN loss: 0.17123842239379883\n","[Iteration 609/720] TRAIN loss: 0.4350709021091461\n","[Iteration 610/720] TRAIN loss: 0.18726949393749237\n","[Iteration 611/720] TRAIN loss: 0.2589085102081299\n","[Iteration 612/720] TRAIN loss: 0.2727169990539551\n","[Iteration 613/720] TRAIN loss: 0.4401795268058777\n","[Iteration 614/720] TRAIN loss: 0.20658913254737854\n","[Iteration 615/720] TRAIN loss: 0.23859843611717224\n","[Iteration 616/720] TRAIN loss: 0.19161075353622437\n","[Iteration 617/720] TRAIN loss: 0.32628515362739563\n","[Iteration 618/720] TRAIN loss: 0.279305636882782\n","[Iteration 619/720] TRAIN loss: 0.41200608015060425\n","[Iteration 620/720] TRAIN loss: 0.2232225388288498\n","[Iteration 621/720] TRAIN loss: 0.22494180500507355\n","[Iteration 622/720] TRAIN loss: 0.3336862325668335\n","[Iteration 623/720] TRAIN loss: 0.1934511661529541\n","[Iteration 624/720] TRAIN loss: 0.14448972046375275\n","[Iteration 625/720] TRAIN loss: 0.31767407059669495\n","[Iteration 626/720] TRAIN loss: 0.2716507911682129\n","[Iteration 627/720] TRAIN loss: 0.2805313169956207\n","[Iteration 628/720] TRAIN loss: 0.33840927481651306\n","[Iteration 629/720] TRAIN loss: 0.16666629910469055\n","[Iteration 630/720] TRAIN loss: 0.2119908630847931\n","[Iteration 631/720] TRAIN loss: 0.29017189145088196\n","[Iteration 632/720] TRAIN loss: 0.23178038001060486\n","[Iteration 633/720] TRAIN loss: 0.2289905846118927\n","[Iteration 634/720] TRAIN loss: 0.3176816403865814\n","[Iteration 635/720] TRAIN loss: 0.3244094252586365\n","[Iteration 636/720] TRAIN loss: 0.22992625832557678\n","[Iteration 637/720] TRAIN loss: 0.2717677056789398\n","[Iteration 638/720] TRAIN loss: 0.25179603695869446\n","[Iteration 639/720] TRAIN loss: 0.33810847997665405\n","[Iteration 640/720] TRAIN loss: 0.1593516319990158\n","[Iteration 641/720] TRAIN loss: 0.21667566895484924\n","[Iteration 642/720] TRAIN loss: 0.28053373098373413\n","[Iteration 643/720] TRAIN loss: 0.42576295137405396\n","[Iteration 644/720] TRAIN loss: 0.4919350743293762\n","[Iteration 645/720] TRAIN loss: 0.19555044174194336\n","[Iteration 646/720] TRAIN loss: 0.38618147373199463\n","[Iteration 647/720] TRAIN loss: 0.31944942474365234\n","[Iteration 648/720] TRAIN loss: 0.6331887245178223\n","[Iteration 649/720] TRAIN loss: 0.44762173295021057\n","[Iteration 650/720] TRAIN loss: 0.31337350606918335\n","[Iteration 651/720] TRAIN loss: 0.30699291825294495\n","[Iteration 652/720] TRAIN loss: 0.21092066168785095\n","[Iteration 653/720] TRAIN loss: 0.3165991008281708\n","[Iteration 654/720] TRAIN loss: 0.3349606692790985\n","[Iteration 655/720] TRAIN loss: 0.22979097068309784\n","[Iteration 656/720] TRAIN loss: 0.21833840012550354\n","[Iteration 657/720] TRAIN loss: 0.3570941090583801\n","[Iteration 658/720] TRAIN loss: 0.31895995140075684\n","[Iteration 659/720] TRAIN loss: 0.2766842544078827\n","[Iteration 660/720] TRAIN loss: 0.307343989610672\n","[Iteration 661/720] TRAIN loss: 0.17174777388572693\n","[Iteration 662/720] TRAIN loss: 0.6638942956924438\n","[Iteration 663/720] TRAIN loss: 0.22987771034240723\n","[Iteration 664/720] TRAIN loss: 0.23723194003105164\n","[Iteration 665/720] TRAIN loss: 0.2688547968864441\n","[Iteration 666/720] TRAIN loss: 0.34094420075416565\n","[Iteration 667/720] TRAIN loss: 0.26846957206726074\n","[Iteration 668/720] TRAIN loss: 0.3228282332420349\n","[Iteration 669/720] TRAIN loss: 0.278254896402359\n","[Iteration 670/720] TRAIN loss: 0.39693912863731384\n","[Iteration 671/720] TRAIN loss: 0.37039726972579956\n","[Iteration 672/720] TRAIN loss: 0.2970356345176697\n","[Iteration 673/720] TRAIN loss: 0.2941329777240753\n","[Iteration 674/720] TRAIN loss: 0.2134551703929901\n","[Iteration 675/720] TRAIN loss: 0.18890944123268127\n","[Iteration 676/720] TRAIN loss: 0.2979471683502197\n","[Iteration 677/720] TRAIN loss: 0.2598133087158203\n","[Iteration 678/720] TRAIN loss: 0.2664487063884735\n","[Iteration 679/720] TRAIN loss: 0.48123446106910706\n","[Iteration 680/720] TRAIN loss: 0.2476256787776947\n","[Iteration 681/720] TRAIN loss: 0.32187700271606445\n","[Iteration 682/720] TRAIN loss: 0.2051330804824829\n","[Iteration 683/720] TRAIN loss: 0.21290656924247742\n","[Iteration 684/720] TRAIN loss: 0.35428276658058167\n","[Iteration 685/720] TRAIN loss: 0.22435982525348663\n","[Iteration 686/720] TRAIN loss: 0.15952667593955994\n","[Iteration 687/720] TRAIN loss: 0.20437276363372803\n","[Iteration 688/720] TRAIN loss: 0.3531912863254547\n","[Iteration 689/720] TRAIN loss: 0.33928149938583374\n","[Iteration 690/720] TRAIN loss: 0.1420561969280243\n","[Iteration 691/720] TRAIN loss: 0.21892115473747253\n","[Iteration 692/720] TRAIN loss: 0.2947571873664856\n","[Iteration 693/720] TRAIN loss: 0.41381630301475525\n","[Iteration 694/720] TRAIN loss: 0.22196336090564728\n","[Iteration 695/720] TRAIN loss: 0.25054115056991577\n","[Iteration 696/720] TRAIN loss: 0.16702276468276978\n","[Iteration 697/720] TRAIN loss: 0.34990325570106506\n","[Iteration 698/720] TRAIN loss: 0.18665364384651184\n","[Iteration 699/720] TRAIN loss: 0.2324952781200409\n","[Iteration 700/720] TRAIN loss: 0.25730210542678833\n","[Iteration 701/720] TRAIN loss: 0.1725381314754486\n","[Iteration 702/720] TRAIN loss: 0.5227700471878052\n","[Iteration 703/720] TRAIN loss: 0.1732381135225296\n","[Iteration 704/720] TRAIN loss: 0.5668352246284485\n","[Iteration 705/720] TRAIN loss: 0.1961037963628769\n","[Iteration 706/720] TRAIN loss: 0.3403436541557312\n","[Iteration 707/720] TRAIN loss: 0.25849565863609314\n","[Iteration 708/720] TRAIN loss: 0.2386862337589264\n","[Iteration 709/720] TRAIN loss: 0.15978103876113892\n","[Iteration 710/720] TRAIN loss: 0.2954244017601013\n","[Iteration 711/720] TRAIN loss: 0.3064577579498291\n","[Iteration 712/720] TRAIN loss: 0.20070946216583252\n","[Iteration 713/720] TRAIN loss: 0.1795930713415146\n","[Iteration 714/720] TRAIN loss: 0.164108008146286\n","[Iteration 715/720] TRAIN loss: 0.2165026217699051\n","[Iteration 716/720] TRAIN loss: 0.3606671690940857\n","[Iteration 717/720] TRAIN loss: 0.18193337321281433\n","[Iteration 718/720] TRAIN loss: 0.30219539999961853\n","[Iteration 719/720] TRAIN loss: 0.5706369876861572\n","[Iteration 720/720] TRAIN loss: 0.68413245677948\n","[EPOCH 1/1] TRAIN acc/loss: 1.0/0.68413245677948\n","[EPOCH 1/1] VAL acc/loss: 0.9755555555555557/0.23812197148799896\n","FINISH.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DeEYJLcRAyBj","colab":{}},"source":["'''\n","print(dataset.__len__())\n","print(dataset.shape)\n","train_dataset = dataset[:20]\n","val_dataset = dataset[20:]\n","\n","print(train_dataset.__len__())\n","print(val_dataset.__len__())\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n","\n","#for i, sample in enumerate(train_loader):\n","#    print(sample[\"images\"][0].shape)\n","#    print(sample[\"labels\"][0].shape)\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4)\n","\n","#solver.train(model, train_loader, val_loader, num_epochs=2, log_nth=1000)\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8S9-1x0zbHZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"81245250-50a8-4747-ce4a-78977457be7f","executionInfo":{"status":"ok","timestamp":1575363471542,"user_tz":-60,"elapsed":433409,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}}},"source":["test_data_location = [\"/content/drive/My Drive/FaceForensics_Sequences/FaceForensics_Testset/original_sequences/youtube/c40/sequences_299x299_5seq@10frames_skip_5_uniform\",\n","                 \"/content/drive/My Drive/FaceForensics_Sequences/FaceForensics_Testset/manipulated_sequences/Deepfakes/c40/sequences_299x299_5seq@10frames_skip_5_uniform\"]\n","test_dataset = FaceForensicsImagesDataset(test_data_location, transform=ToTensor())\n","\n","test_indices = range(len(test_dataset))\n","\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, \n","                                           sampler=test_sampler)\n","\n","print(\"Length of test dataset: {}\".format(len(test_dataset)))\n","\n","from torch.autograd import Variable\n","model.eval()  # EVAL mode (for dropout, batchnorm, etc.)\n","with torch.no_grad():\n","    test_losses = []\n","    test_acc = []\n","    for sample in test_loader:\n","        xb = sample[\"image\"]\n","        yb = sample[\"label\"]\n","\n","        xb, yb = Variable(xb), Variable(yb)\n","        #if str(device) != 'cpu':\n","        xb, yb = xb.cuda(), yb.cuda()\n","\n","\n","        #xb, yb = wrap_data(xb, yb, device)\n","\n","        # FORWARD PASS --> Loss calculation\n","        loss_func = torch.nn.CrossEntropyLoss()\n","        scores = model(xb)\n","        loss = loss_func(scores, yb)\n","        loss = loss.data.cpu().numpy()\n","        test_losses.append(loss)\n","      \n","        _, preds = torch.max(scores, 1) # select highest value as the predicted class\n","        #y_mask = yb >= 0 # do not allow \"-1\" segmentation value\n","        acc = np.mean((preds == yb).data.cpu().numpy())  # check if prediction is correct + average of it for all N inputs\n","\n","        test_acc.append(acc)\n","\n","        print(\"---intermediate test acc: {} loss: {}\".format(acc, loss))\n","\n","    test_loss = np.mean(test_losses)\n","    test_acc = np.mean(test_acc)\n","\n","    print(\"TEST: acc: {} loss: {}\".format(test_acc, test_loss))\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Length of test dataset: 998\n","---intermediate test acc: 1.0 loss: 0.19158989191055298\n","---intermediate test acc: 1.0 loss: 0.4565700590610504\n","---intermediate test acc: 1.0 loss: 0.1792561411857605\n","---intermediate test acc: 1.0 loss: 0.3902878761291504\n","---intermediate test acc: 1.0 loss: 0.3729513883590698\n","---intermediate test acc: 1.0 loss: 0.2307721972465515\n","---intermediate test acc: 1.0 loss: 0.43468016386032104\n","---intermediate test acc: 1.0 loss: 0.285015344619751\n","---intermediate test acc: 1.0 loss: 0.3550790548324585\n","---intermediate test acc: 1.0 loss: 0.6074437499046326\n","---intermediate test acc: 1.0 loss: 0.13549774885177612\n","---intermediate test acc: 1.0 loss: 0.24583011865615845\n","---intermediate test acc: 1.0 loss: 0.24725943803787231\n","---intermediate test acc: 1.0 loss: 0.12277400493621826\n","---intermediate test acc: 1.0 loss: 0.07096230983734131\n","---intermediate test acc: 1.0 loss: 0.13203716278076172\n","---intermediate test acc: 1.0 loss: 0.1577167510986328\n","---intermediate test acc: 1.0 loss: 0.419045627117157\n","---intermediate test acc: 1.0 loss: 0.46127942204475403\n","---intermediate test acc: 1.0 loss: 0.47015100717544556\n","---intermediate test acc: 1.0 loss: 0.35315200686454773\n","---intermediate test acc: 0.0 loss: 0.8579548597335815\n","---intermediate test acc: 1.0 loss: 0.5701591968536377\n","---intermediate test acc: 1.0 loss: 0.17151260375976562\n","---intermediate test acc: 1.0 loss: 0.22850292921066284\n","---intermediate test acc: 1.0 loss: 0.2779201865196228\n","---intermediate test acc: 1.0 loss: 0.0952223539352417\n","---intermediate test acc: 1.0 loss: 0.2232973575592041\n","---intermediate test acc: 1.0 loss: 0.13704752922058105\n","---intermediate test acc: 1.0 loss: 0.19388717412948608\n","---intermediate test acc: 1.0 loss: 0.5529922842979431\n","---intermediate test acc: 1.0 loss: 0.39594998955726624\n","---intermediate test acc: 1.0 loss: 0.26210397481918335\n","---intermediate test acc: 1.0 loss: 0.13350850343704224\n","---intermediate test acc: 1.0 loss: 0.07484638690948486\n","---intermediate test acc: 1.0 loss: 0.26987510919570923\n","---intermediate test acc: 1.0 loss: 0.38849249482154846\n","---intermediate test acc: 1.0 loss: 0.2775825262069702\n","---intermediate test acc: 1.0 loss: 0.12990045547485352\n","---intermediate test acc: 1.0 loss: 0.4961389899253845\n","---intermediate test acc: 1.0 loss: 0.33434706926345825\n","---intermediate test acc: 1.0 loss: 0.09182465076446533\n","---intermediate test acc: 1.0 loss: 0.44086915254592896\n","---intermediate test acc: 1.0 loss: 0.40615034103393555\n","---intermediate test acc: 1.0 loss: 0.3636888563632965\n","---intermediate test acc: 1.0 loss: 0.41251662373542786\n","---intermediate test acc: 1.0 loss: 0.18368059396743774\n","---intermediate test acc: 1.0 loss: 0.4065547585487366\n","---intermediate test acc: 1.0 loss: 0.1637020707130432\n","---intermediate test acc: 1.0 loss: 0.18792498111724854\n","---intermediate test acc: 1.0 loss: 0.4331708252429962\n","---intermediate test acc: 1.0 loss: 0.13000881671905518\n","---intermediate test acc: 1.0 loss: 0.5162750482559204\n","---intermediate test acc: 1.0 loss: 0.11787831783294678\n","---intermediate test acc: 1.0 loss: 0.20915824174880981\n","---intermediate test acc: 1.0 loss: 0.23471760749816895\n","---intermediate test acc: 1.0 loss: 0.29249101877212524\n","---intermediate test acc: 1.0 loss: 0.09891748428344727\n","---intermediate test acc: 1.0 loss: 0.4177551567554474\n","---intermediate test acc: 1.0 loss: 0.15438556671142578\n","---intermediate test acc: 1.0 loss: 0.11258649826049805\n","---intermediate test acc: 1.0 loss: 0.2683866620063782\n","---intermediate test acc: 1.0 loss: 0.19378125667572021\n","---intermediate test acc: 1.0 loss: 0.2786140441894531\n","---intermediate test acc: 1.0 loss: 0.303891122341156\n","---intermediate test acc: 1.0 loss: 0.1532827615737915\n","---intermediate test acc: 1.0 loss: 0.2039186954498291\n","---intermediate test acc: 1.0 loss: 0.6636776328086853\n","---intermediate test acc: 1.0 loss: 0.35513973236083984\n","---intermediate test acc: 1.0 loss: 0.14494264125823975\n","---intermediate test acc: 1.0 loss: 0.49090319871902466\n","---intermediate test acc: 1.0 loss: 0.20135736465454102\n","---intermediate test acc: 0.0 loss: 0.9885591268539429\n","---intermediate test acc: 1.0 loss: 0.4480396807193756\n","---intermediate test acc: 1.0 loss: 0.11729001998901367\n","---intermediate test acc: 1.0 loss: 0.2895764708518982\n","---intermediate test acc: 1.0 loss: 0.1586322784423828\n","---intermediate test acc: 1.0 loss: 0.39833348989486694\n","---intermediate test acc: 1.0 loss: 0.10635578632354736\n","---intermediate test acc: 1.0 loss: 0.3408946692943573\n","---intermediate test acc: 1.0 loss: 0.2747840881347656\n","---intermediate test acc: 1.0 loss: 0.1350727677345276\n","---intermediate test acc: 1.0 loss: 0.1940981149673462\n","---intermediate test acc: 0.0 loss: 0.8050916790962219\n","---intermediate test acc: 1.0 loss: 0.24764281511306763\n","---intermediate test acc: 1.0 loss: 0.5462737083435059\n","---intermediate test acc: 1.0 loss: 0.6302289962768555\n","---intermediate test acc: 1.0 loss: 0.25515085458755493\n","---intermediate test acc: 1.0 loss: 0.06292927265167236\n","---intermediate test acc: 1.0 loss: 0.17398494482040405\n","---intermediate test acc: 1.0 loss: 0.1526733636856079\n","---intermediate test acc: 1.0 loss: 0.20831245183944702\n","---intermediate test acc: 1.0 loss: 0.615941047668457\n","---intermediate test acc: 1.0 loss: 0.4558973014354706\n","---intermediate test acc: 1.0 loss: 0.2819939851760864\n","---intermediate test acc: 1.0 loss: 0.44660139083862305\n","---intermediate test acc: 1.0 loss: 0.09010004997253418\n","---intermediate test acc: 1.0 loss: 0.10398602485656738\n","---intermediate test acc: 1.0 loss: 0.42026686668395996\n","---intermediate test acc: 1.0 loss: 0.5400248765945435\n","---intermediate test acc: 1.0 loss: 0.12603580951690674\n","---intermediate test acc: 1.0 loss: 0.3308093845844269\n","---intermediate test acc: 1.0 loss: 0.3786226809024811\n","---intermediate test acc: 1.0 loss: 0.42352908849716187\n","---intermediate test acc: 1.0 loss: 0.2696331739425659\n","---intermediate test acc: 1.0 loss: 0.1054849624633789\n","---intermediate test acc: 1.0 loss: 0.37375983595848083\n","---intermediate test acc: 1.0 loss: 0.18506276607513428\n","---intermediate test acc: 1.0 loss: 0.41669178009033203\n","---intermediate test acc: 1.0 loss: 0.6439273953437805\n","---intermediate test acc: 1.0 loss: 0.4483804702758789\n","---intermediate test acc: 1.0 loss: 0.21591180562973022\n","---intermediate test acc: 1.0 loss: 0.14109981060028076\n","---intermediate test acc: 1.0 loss: 0.14802515506744385\n","---intermediate test acc: 1.0 loss: 0.35162457823753357\n","---intermediate test acc: 1.0 loss: 0.3333010971546173\n","---intermediate test acc: 1.0 loss: 0.31794100999832153\n","---intermediate test acc: 1.0 loss: 0.19326525926589966\n","---intermediate test acc: 1.0 loss: 0.23845887184143066\n","---intermediate test acc: 1.0 loss: 0.09072303771972656\n","---intermediate test acc: 1.0 loss: 0.640938401222229\n","---intermediate test acc: 1.0 loss: 0.2402682900428772\n","---intermediate test acc: 1.0 loss: 0.2794548273086548\n","---intermediate test acc: 1.0 loss: 0.09076392650604248\n","---intermediate test acc: 1.0 loss: 0.22124260663986206\n","---intermediate test acc: 1.0 loss: 0.6464576721191406\n","---intermediate test acc: 1.0 loss: 0.4572370648384094\n","---intermediate test acc: 1.0 loss: 0.2415471076965332\n","---intermediate test acc: 1.0 loss: 0.17081224918365479\n","---intermediate test acc: 1.0 loss: 0.12064683437347412\n","---intermediate test acc: 1.0 loss: 0.369099497795105\n","---intermediate test acc: 1.0 loss: 0.2042110562324524\n","---intermediate test acc: 1.0 loss: 0.40483883023262024\n","---intermediate test acc: 1.0 loss: 0.5486879348754883\n","---intermediate test acc: 1.0 loss: 0.4297609031200409\n","---intermediate test acc: 1.0 loss: 0.37436315417289734\n","---intermediate test acc: 1.0 loss: 0.1892276406288147\n","---intermediate test acc: 1.0 loss: 0.10701406002044678\n","---intermediate test acc: 1.0 loss: 0.19271737337112427\n","---intermediate test acc: 1.0 loss: 0.35578957200050354\n","---intermediate test acc: 1.0 loss: 0.14096903800964355\n","---intermediate test acc: 1.0 loss: 0.1537107229232788\n","---intermediate test acc: 1.0 loss: 0.24829477071762085\n","---intermediate test acc: 1.0 loss: 0.5180771350860596\n","---intermediate test acc: 0.0 loss: 1.128241777420044\n","---intermediate test acc: 1.0 loss: 0.2634900212287903\n","---intermediate test acc: 1.0 loss: 0.32235589623451233\n","---intermediate test acc: 1.0 loss: 0.08370864391326904\n","---intermediate test acc: 1.0 loss: 0.2053830623626709\n","---intermediate test acc: 1.0 loss: 0.1374368667602539\n","---intermediate test acc: 1.0 loss: 0.37918683886528015\n","---intermediate test acc: 1.0 loss: 0.16417568922042847\n","---intermediate test acc: 1.0 loss: 0.171617329120636\n","---intermediate test acc: 1.0 loss: 0.2582578659057617\n","---intermediate test acc: 1.0 loss: 0.2746361494064331\n","---intermediate test acc: 1.0 loss: 0.2784467935562134\n","---intermediate test acc: 1.0 loss: 0.41381704807281494\n","---intermediate test acc: 1.0 loss: 0.2719793915748596\n","---intermediate test acc: 1.0 loss: 0.05935966968536377\n","---intermediate test acc: 1.0 loss: 0.10988223552703857\n","---intermediate test acc: 1.0 loss: 0.09870874881744385\n","---intermediate test acc: 1.0 loss: 0.09238588809967041\n","---intermediate test acc: 1.0 loss: 0.2585068941116333\n","---intermediate test acc: 1.0 loss: 0.16681766510009766\n","---intermediate test acc: 1.0 loss: 0.14025026559829712\n","---intermediate test acc: 1.0 loss: 0.2327176332473755\n","---intermediate test acc: 1.0 loss: 0.36859413981437683\n","---intermediate test acc: 1.0 loss: 0.4272332787513733\n","---intermediate test acc: 1.0 loss: 0.5205919742584229\n","---intermediate test acc: 1.0 loss: 0.2604023218154907\n","---intermediate test acc: 1.0 loss: 0.22316014766693115\n","---intermediate test acc: 1.0 loss: 0.35715678334236145\n","---intermediate test acc: 1.0 loss: 0.21264994144439697\n","---intermediate test acc: 1.0 loss: 0.15175455808639526\n","---intermediate test acc: 1.0 loss: 0.1601298451423645\n","---intermediate test acc: 1.0 loss: 0.29765141010284424\n","---intermediate test acc: 1.0 loss: 0.2394511103630066\n","---intermediate test acc: 1.0 loss: 0.13716429471969604\n","---intermediate test acc: 1.0 loss: 0.20153504610061646\n","---intermediate test acc: 1.0 loss: 0.3407187759876251\n","---intermediate test acc: 1.0 loss: 0.45439422130584717\n","---intermediate test acc: 1.0 loss: 0.16177833080291748\n","---intermediate test acc: 1.0 loss: 0.05333125591278076\n","---intermediate test acc: 1.0 loss: 0.18354201316833496\n","---intermediate test acc: 1.0 loss: 0.13516193628311157\n","---intermediate test acc: 1.0 loss: 0.48271024227142334\n","---intermediate test acc: 1.0 loss: 0.22122693061828613\n","---intermediate test acc: 1.0 loss: 0.1759241819381714\n","---intermediate test acc: 1.0 loss: 0.2750990390777588\n","---intermediate test acc: 1.0 loss: 0.4185299575328827\n","---intermediate test acc: 1.0 loss: 0.18178606033325195\n","---intermediate test acc: 1.0 loss: 0.20742952823638916\n","---intermediate test acc: 1.0 loss: 0.45131388306617737\n","---intermediate test acc: 1.0 loss: 0.16540926694869995\n","---intermediate test acc: 1.0 loss: 0.2897253632545471\n","---intermediate test acc: 1.0 loss: 0.1727520227432251\n","---intermediate test acc: 1.0 loss: 0.2818450331687927\n","---intermediate test acc: 1.0 loss: 0.18649280071258545\n","---intermediate test acc: 1.0 loss: 0.30511391162872314\n","---intermediate test acc: 1.0 loss: 0.36451348662376404\n","---intermediate test acc: 1.0 loss: 0.45977017283439636\n","---intermediate test acc: 1.0 loss: 0.2996617555618286\n","---intermediate test acc: 1.0 loss: 0.24790799617767334\n","---intermediate test acc: 1.0 loss: 0.10561192035675049\n","---intermediate test acc: 1.0 loss: 0.5192107558250427\n","---intermediate test acc: 1.0 loss: 0.2656979560852051\n","---intermediate test acc: 1.0 loss: 0.24394863843917847\n","---intermediate test acc: 1.0 loss: 0.12835395336151123\n","---intermediate test acc: 1.0 loss: 0.46127986907958984\n","---intermediate test acc: 0.0 loss: 0.8002451658248901\n","---intermediate test acc: 1.0 loss: 0.3536868095397949\n","---intermediate test acc: 1.0 loss: 0.35523340106010437\n","---intermediate test acc: 1.0 loss: 0.15017563104629517\n","---intermediate test acc: 1.0 loss: 0.3852956295013428\n","---intermediate test acc: 1.0 loss: 0.26315921545028687\n","---intermediate test acc: 1.0 loss: 0.18928515911102295\n","---intermediate test acc: 1.0 loss: 0.23341333866119385\n","---intermediate test acc: 1.0 loss: 0.4237947463989258\n","---intermediate test acc: 1.0 loss: 0.2176731824874878\n","---intermediate test acc: 1.0 loss: 0.2365747094154358\n","---intermediate test acc: 1.0 loss: 0.4057508409023285\n","---intermediate test acc: 1.0 loss: 0.18939566612243652\n","---intermediate test acc: 1.0 loss: 0.25058531761169434\n","---intermediate test acc: 1.0 loss: 0.5329651236534119\n","---intermediate test acc: 1.0 loss: 0.42846256494522095\n","---intermediate test acc: 0.0 loss: 0.7130565047264099\n","---intermediate test acc: 1.0 loss: 0.623132050037384\n","---intermediate test acc: 1.0 loss: 0.08350992202758789\n","---intermediate test acc: 1.0 loss: 0.4176411032676697\n","---intermediate test acc: 1.0 loss: 0.5081329345703125\n","---intermediate test acc: 1.0 loss: 0.0543595552444458\n","---intermediate test acc: 1.0 loss: 0.45289546251296997\n","---intermediate test acc: 1.0 loss: 0.33840399980545044\n","---intermediate test acc: 1.0 loss: 0.08373451232910156\n","---intermediate test acc: 1.0 loss: 0.2680894732475281\n","---intermediate test acc: 1.0 loss: 0.3592309057712555\n","---intermediate test acc: 1.0 loss: 0.2987685203552246\n","---intermediate test acc: 1.0 loss: 0.5303129553794861\n","---intermediate test acc: 1.0 loss: 0.16187071800231934\n","---intermediate test acc: 1.0 loss: 0.3124619126319885\n","---intermediate test acc: 1.0 loss: 0.5485862493515015\n","---intermediate test acc: 1.0 loss: 0.2050929069519043\n","---intermediate test acc: 1.0 loss: 0.31476891040802\n","---intermediate test acc: 1.0 loss: 0.23696041107177734\n","---intermediate test acc: 1.0 loss: 0.6793685555458069\n","---intermediate test acc: 1.0 loss: 0.20550191402435303\n","---intermediate test acc: 1.0 loss: 0.4017206132411957\n","---intermediate test acc: 1.0 loss: 0.20508897304534912\n","---intermediate test acc: 1.0 loss: 0.4211215674877167\n","---intermediate test acc: 1.0 loss: 0.2586061358451843\n","---intermediate test acc: 1.0 loss: 0.20899921655654907\n","---intermediate test acc: 1.0 loss: 0.11351585388183594\n","---intermediate test acc: 1.0 loss: 0.46775585412979126\n","---intermediate test acc: 1.0 loss: 0.3326736390590668\n","---intermediate test acc: 1.0 loss: 0.14700764417648315\n","---intermediate test acc: 1.0 loss: 0.17586207389831543\n","---intermediate test acc: 1.0 loss: 0.26343488693237305\n","---intermediate test acc: 1.0 loss: 0.32632625102996826\n","---intermediate test acc: 1.0 loss: 0.1156618595123291\n","---intermediate test acc: 1.0 loss: 0.45237433910369873\n","---intermediate test acc: 1.0 loss: 0.09283685684204102\n","---intermediate test acc: 1.0 loss: 0.2176406979560852\n","---intermediate test acc: 1.0 loss: 0.11275672912597656\n","---intermediate test acc: 1.0 loss: 0.4209149479866028\n","---intermediate test acc: 1.0 loss: 0.11264002323150635\n","---intermediate test acc: 0.0 loss: 0.7373179197311401\n","---intermediate test acc: 0.0 loss: 0.7796218991279602\n","---intermediate test acc: 1.0 loss: 0.2352433204650879\n","---intermediate test acc: 1.0 loss: 0.24955499172210693\n","---intermediate test acc: 1.0 loss: 0.5765759944915771\n","---intermediate test acc: 1.0 loss: 0.3263905644416809\n","---intermediate test acc: 1.0 loss: 0.4445865750312805\n","---intermediate test acc: 1.0 loss: 0.5021916627883911\n","---intermediate test acc: 1.0 loss: 0.32206398248672485\n","---intermediate test acc: 1.0 loss: 0.09094810485839844\n","---intermediate test acc: 1.0 loss: 0.4889565706253052\n","---intermediate test acc: 1.0 loss: 0.5409843921661377\n","---intermediate test acc: 1.0 loss: 0.351675808429718\n","---intermediate test acc: 1.0 loss: 0.24405509233474731\n","---intermediate test acc: 1.0 loss: 0.08720231056213379\n","---intermediate test acc: 1.0 loss: 0.2369849681854248\n","---intermediate test acc: 1.0 loss: 0.5504026412963867\n","---intermediate test acc: 1.0 loss: 0.14156371355056763\n","---intermediate test acc: 1.0 loss: 0.242983877658844\n","---intermediate test acc: 1.0 loss: 0.3065754175186157\n","---intermediate test acc: 1.0 loss: 0.15664607286453247\n","---intermediate test acc: 1.0 loss: 0.5644616484642029\n","---intermediate test acc: 1.0 loss: 0.4261135458946228\n","---intermediate test acc: 1.0 loss: 0.49278128147125244\n","---intermediate test acc: 1.0 loss: 0.48898136615753174\n","---intermediate test acc: 1.0 loss: 0.34860554337501526\n","---intermediate test acc: 1.0 loss: 0.19565361738204956\n","---intermediate test acc: 1.0 loss: 0.128584623336792\n","---intermediate test acc: 1.0 loss: 0.2170223593711853\n","---intermediate test acc: 1.0 loss: 0.33410272002220154\n","---intermediate test acc: 1.0 loss: 0.31440970301628113\n","---intermediate test acc: 1.0 loss: 0.38143831491470337\n","---intermediate test acc: 0.0 loss: 0.7666049599647522\n","---intermediate test acc: 1.0 loss: 0.13382482528686523\n","---intermediate test acc: 1.0 loss: 0.5894078016281128\n","---intermediate test acc: 1.0 loss: 0.08588683605194092\n","---intermediate test acc: 1.0 loss: 0.3739912807941437\n","---intermediate test acc: 1.0 loss: 0.2838379144668579\n","---intermediate test acc: 0.0 loss: 0.746552050113678\n","---intermediate test acc: 1.0 loss: 0.3718532621860504\n","---intermediate test acc: 1.0 loss: 0.15905296802520752\n","---intermediate test acc: 1.0 loss: 0.3146744966506958\n","---intermediate test acc: 1.0 loss: 0.39809975028038025\n","---intermediate test acc: 1.0 loss: 0.18958616256713867\n","---intermediate test acc: 1.0 loss: 0.182267963886261\n","---intermediate test acc: 1.0 loss: 0.2020360231399536\n","---intermediate test acc: 1.0 loss: 0.3943442106246948\n","---intermediate test acc: 1.0 loss: 0.30328720808029175\n","---intermediate test acc: 1.0 loss: 0.13208341598510742\n","---intermediate test acc: 1.0 loss: 0.055126309394836426\n","---intermediate test acc: 1.0 loss: 0.48498526215553284\n","---intermediate test acc: 1.0 loss: 0.0796881914138794\n","---intermediate test acc: 1.0 loss: 0.201529860496521\n","---intermediate test acc: 1.0 loss: 0.19135767221450806\n","---intermediate test acc: 1.0 loss: 0.08348870277404785\n","---intermediate test acc: 1.0 loss: 0.3842596113681793\n","---intermediate test acc: 1.0 loss: 0.28689467906951904\n","---intermediate test acc: 1.0 loss: 0.20429134368896484\n","---intermediate test acc: 1.0 loss: 0.3274231553077698\n","---intermediate test acc: 1.0 loss: 0.5351679921150208\n","---intermediate test acc: 1.0 loss: 0.1150507926940918\n","---intermediate test acc: 1.0 loss: 0.18029308319091797\n","---intermediate test acc: 1.0 loss: 0.1779038906097412\n","---intermediate test acc: 1.0 loss: 0.18138033151626587\n","---intermediate test acc: 1.0 loss: 0.5900688767433167\n","---intermediate test acc: 1.0 loss: 0.20531046390533447\n","---intermediate test acc: 1.0 loss: 0.049823641777038574\n","---intermediate test acc: 0.0 loss: 0.8104314208030701\n","---intermediate test acc: 1.0 loss: 0.4849037230014801\n","---intermediate test acc: 1.0 loss: 0.06959950923919678\n","---intermediate test acc: 1.0 loss: 0.3237253427505493\n","---intermediate test acc: 1.0 loss: 0.5984078645706177\n","---intermediate test acc: 1.0 loss: 0.1020350456237793\n","---intermediate test acc: 1.0 loss: 0.4317324757575989\n","---intermediate test acc: 1.0 loss: 0.47853976488113403\n","---intermediate test acc: 1.0 loss: 0.1832050085067749\n","---intermediate test acc: 1.0 loss: 0.4399399757385254\n","---intermediate test acc: 1.0 loss: 0.21328580379486084\n","---intermediate test acc: 1.0 loss: 0.62474524974823\n","---intermediate test acc: 1.0 loss: 0.206653892993927\n","---intermediate test acc: 1.0 loss: 0.23888510465621948\n","---intermediate test acc: 1.0 loss: 0.6565272808074951\n","---intermediate test acc: 1.0 loss: 0.18123549222946167\n","---intermediate test acc: 1.0 loss: 0.4671279191970825\n","---intermediate test acc: 1.0 loss: 0.34687668085098267\n","---intermediate test acc: 1.0 loss: 0.4069885313510895\n","---intermediate test acc: 1.0 loss: 0.2587065100669861\n","---intermediate test acc: 1.0 loss: 0.4126403033733368\n","---intermediate test acc: 1.0 loss: 0.09927499294281006\n","---intermediate test acc: 1.0 loss: 0.1267387866973877\n","---intermediate test acc: 1.0 loss: 0.2685464024543762\n","---intermediate test acc: 1.0 loss: 0.17542940378189087\n","---intermediate test acc: 1.0 loss: 0.15929144620895386\n","---intermediate test acc: 1.0 loss: 0.09216105937957764\n","---intermediate test acc: 1.0 loss: 0.39559534192085266\n","---intermediate test acc: 1.0 loss: 0.25270944833755493\n","---intermediate test acc: 1.0 loss: 0.13766145706176758\n","---intermediate test acc: 1.0 loss: 0.31264200806617737\n","---intermediate test acc: 1.0 loss: 0.15446096658706665\n","---intermediate test acc: 1.0 loss: 0.34541261196136475\n","---intermediate test acc: 1.0 loss: 0.2614111304283142\n","---intermediate test acc: 1.0 loss: 0.2351951003074646\n","---intermediate test acc: 1.0 loss: 0.41997408866882324\n","---intermediate test acc: 1.0 loss: 0.12998461723327637\n","---intermediate test acc: 1.0 loss: 0.6532214283943176\n","---intermediate test acc: 1.0 loss: 0.40078866481781006\n","---intermediate test acc: 1.0 loss: 0.18280506134033203\n","---intermediate test acc: 0.0 loss: 0.7771601676940918\n","---intermediate test acc: 1.0 loss: 0.3819481134414673\n","---intermediate test acc: 1.0 loss: 0.1188199520111084\n","---intermediate test acc: 1.0 loss: 0.3333270847797394\n","---intermediate test acc: 1.0 loss: 0.1757122278213501\n","---intermediate test acc: 1.0 loss: 0.14279955625534058\n","---intermediate test acc: 1.0 loss: 0.11851179599761963\n","---intermediate test acc: 1.0 loss: 0.39042338728904724\n","---intermediate test acc: 1.0 loss: 0.1812567114830017\n","---intermediate test acc: 1.0 loss: 0.07791507244110107\n","---intermediate test acc: 1.0 loss: 0.3497345447540283\n","---intermediate test acc: 1.0 loss: 0.11642158031463623\n","---intermediate test acc: 1.0 loss: 0.3484836518764496\n","---intermediate test acc: 1.0 loss: 0.12673473358154297\n","---intermediate test acc: 1.0 loss: 0.09306895732879639\n","---intermediate test acc: 1.0 loss: 0.43283596634864807\n","---intermediate test acc: 1.0 loss: 0.35883674025535583\n","---intermediate test acc: 1.0 loss: 0.3784047067165375\n","---intermediate test acc: 1.0 loss: 0.19941562414169312\n","---intermediate test acc: 1.0 loss: 0.20058375597000122\n","---intermediate test acc: 1.0 loss: 0.2560833692550659\n","---intermediate test acc: 1.0 loss: 0.3834656774997711\n","---intermediate test acc: 1.0 loss: 0.13892316818237305\n","---intermediate test acc: 0.0 loss: 0.8483250737190247\n","---intermediate test acc: 1.0 loss: 0.5833423137664795\n","---intermediate test acc: 1.0 loss: 0.17883682250976562\n","---intermediate test acc: 1.0 loss: 0.10789120197296143\n","---intermediate test acc: 1.0 loss: 0.32385048270225525\n","---intermediate test acc: 1.0 loss: 0.20865744352340698\n","---intermediate test acc: 1.0 loss: 0.3949181139469147\n","---intermediate test acc: 1.0 loss: 0.2330952286720276\n","---intermediate test acc: 1.0 loss: 0.17152881622314453\n","---intermediate test acc: 1.0 loss: 0.6339415907859802\n","---intermediate test acc: 1.0 loss: 0.17136067152023315\n","---intermediate test acc: 1.0 loss: 0.14780831336975098\n","---intermediate test acc: 1.0 loss: 0.3162391185760498\n","---intermediate test acc: 1.0 loss: 0.24585634469985962\n","---intermediate test acc: 1.0 loss: 0.1617174744606018\n","---intermediate test acc: 1.0 loss: 0.17268985509872437\n","---intermediate test acc: 1.0 loss: 0.1214449405670166\n","---intermediate test acc: 1.0 loss: 0.15764260292053223\n","---intermediate test acc: 1.0 loss: 0.5927388668060303\n","---intermediate test acc: 1.0 loss: 0.3290135860443115\n","---intermediate test acc: 1.0 loss: 0.3522300124168396\n","---intermediate test acc: 1.0 loss: 0.23345321416854858\n","---intermediate test acc: 1.0 loss: 0.22518062591552734\n","---intermediate test acc: 1.0 loss: 0.16535186767578125\n","---intermediate test acc: 1.0 loss: 0.23782974481582642\n","---intermediate test acc: 1.0 loss: 0.5492880940437317\n","---intermediate test acc: 1.0 loss: 0.3500073254108429\n","---intermediate test acc: 1.0 loss: 0.20669132471084595\n","---intermediate test acc: 1.0 loss: 0.20140200853347778\n","---intermediate test acc: 1.0 loss: 0.41416704654693604\n","---intermediate test acc: 1.0 loss: 0.3988676071166992\n","---intermediate test acc: 1.0 loss: 0.18288284540176392\n","---intermediate test acc: 0.0 loss: 1.3840677738189697\n","---intermediate test acc: 1.0 loss: 0.17894983291625977\n","---intermediate test acc: 1.0 loss: 0.40967750549316406\n","---intermediate test acc: 1.0 loss: 0.18514764308929443\n","---intermediate test acc: 1.0 loss: 0.12252473831176758\n","---intermediate test acc: 1.0 loss: 0.34679296612739563\n","---intermediate test acc: 1.0 loss: 0.09706544876098633\n","---intermediate test acc: 1.0 loss: 0.1505935788154602\n","---intermediate test acc: 1.0 loss: 0.29246968030929565\n","---intermediate test acc: 1.0 loss: 0.19055616855621338\n","---intermediate test acc: 1.0 loss: 0.25421231985092163\n","---intermediate test acc: 1.0 loss: 0.14685654640197754\n","---intermediate test acc: 1.0 loss: 0.12037456035614014\n","---intermediate test acc: 1.0 loss: 0.1432681679725647\n","---intermediate test acc: 1.0 loss: 0.21073007583618164\n","---intermediate test acc: 1.0 loss: 0.11311876773834229\n","---intermediate test acc: 1.0 loss: 0.27533549070358276\n","---intermediate test acc: 1.0 loss: 0.21000146865844727\n","---intermediate test acc: 1.0 loss: 0.6145912408828735\n","---intermediate test acc: 1.0 loss: 0.15798193216323853\n","---intermediate test acc: 1.0 loss: 0.4217081665992737\n","---intermediate test acc: 1.0 loss: 0.10489308834075928\n","---intermediate test acc: 1.0 loss: 0.16804379224777222\n","---intermediate test acc: 1.0 loss: 0.15521711111068726\n","---intermediate test acc: 1.0 loss: 0.08634138107299805\n","---intermediate test acc: 1.0 loss: 0.19116860628128052\n","---intermediate test acc: 1.0 loss: 0.14486479759216309\n","---intermediate test acc: 1.0 loss: 0.35773900151252747\n","---intermediate test acc: 1.0 loss: 0.6265115737915039\n","---intermediate test acc: 1.0 loss: 0.49460893869400024\n","---intermediate test acc: 1.0 loss: 0.13580358028411865\n","---intermediate test acc: 1.0 loss: 0.28948235511779785\n","---intermediate test acc: 1.0 loss: 0.12661117315292358\n","---intermediate test acc: 1.0 loss: 0.39653560519218445\n","---intermediate test acc: 1.0 loss: 0.20492655038833618\n","---intermediate test acc: 1.0 loss: 0.27582237124443054\n","---intermediate test acc: 1.0 loss: 0.2797100841999054\n","---intermediate test acc: 1.0 loss: 0.21306484937667847\n","---intermediate test acc: 1.0 loss: 0.21263360977172852\n","---intermediate test acc: 1.0 loss: 0.08906972408294678\n","---intermediate test acc: 1.0 loss: 0.15263134241104126\n","---intermediate test acc: 1.0 loss: 0.09864640235900879\n","---intermediate test acc: 1.0 loss: 0.3459652364253998\n","---intermediate test acc: 1.0 loss: 0.2012852430343628\n","---intermediate test acc: 1.0 loss: 0.18450164794921875\n","---intermediate test acc: 1.0 loss: 0.1525154709815979\n","---intermediate test acc: 1.0 loss: 0.2046106457710266\n","---intermediate test acc: 1.0 loss: 0.37846967577934265\n","---intermediate test acc: 1.0 loss: 0.15543293952941895\n","---intermediate test acc: 1.0 loss: 0.1760956048965454\n","---intermediate test acc: 0.0 loss: 1.2155944108963013\n","---intermediate test acc: 1.0 loss: 0.25445497035980225\n","---intermediate test acc: 1.0 loss: 0.2783004641532898\n","---intermediate test acc: 1.0 loss: 0.37792345881462097\n","---intermediate test acc: 1.0 loss: 0.21712416410446167\n","---intermediate test acc: 1.0 loss: 0.4862109422683716\n","---intermediate test acc: 1.0 loss: 0.06676316261291504\n","---intermediate test acc: 1.0 loss: 0.23119324445724487\n","---intermediate test acc: 1.0 loss: 0.3924429416656494\n","---intermediate test acc: 1.0 loss: 0.2218678593635559\n","---intermediate test acc: 1.0 loss: 0.222739577293396\n","---intermediate test acc: 1.0 loss: 0.1637718677520752\n","---intermediate test acc: 1.0 loss: 0.3945251703262329\n","---intermediate test acc: 1.0 loss: 0.3914738893508911\n","---intermediate test acc: 1.0 loss: 0.16900932788848877\n","---intermediate test acc: 1.0 loss: 0.13911211490631104\n","---intermediate test acc: 1.0 loss: 0.22418689727783203\n","---intermediate test acc: 1.0 loss: 0.4651179611682892\n","---intermediate test acc: 1.0 loss: 0.11530756950378418\n","---intermediate test acc: 1.0 loss: 0.47391557693481445\n","---intermediate test acc: 1.0 loss: 0.10860228538513184\n","---intermediate test acc: 1.0 loss: 0.31907394528388977\n","---intermediate test acc: 1.0 loss: 0.1824944019317627\n","---intermediate test acc: 0.0 loss: 0.9187256693840027\n","---intermediate test acc: 1.0 loss: 0.2104589343070984\n","---intermediate test acc: 1.0 loss: 0.25480592250823975\n","---intermediate test acc: 1.0 loss: 0.23737329244613647\n","---intermediate test acc: 1.0 loss: 0.5288407802581787\n","---intermediate test acc: 1.0 loss: 0.11091327667236328\n","---intermediate test acc: 1.0 loss: 0.13941049575805664\n","---intermediate test acc: 1.0 loss: 0.33084818720817566\n","---intermediate test acc: 1.0 loss: 0.6545717716217041\n","---intermediate test acc: 1.0 loss: 0.42310070991516113\n","---intermediate test acc: 1.0 loss: 0.4949723482131958\n","---intermediate test acc: 1.0 loss: 0.10994529724121094\n","---intermediate test acc: 1.0 loss: 0.2679671049118042\n","---intermediate test acc: 1.0 loss: 0.15073257684707642\n","---intermediate test acc: 0.0 loss: 0.8252006769180298\n","---intermediate test acc: 1.0 loss: 0.3841378390789032\n","---intermediate test acc: 1.0 loss: 0.24508273601531982\n","---intermediate test acc: 1.0 loss: 0.3645836114883423\n","---intermediate test acc: 1.0 loss: 0.3232574462890625\n","---intermediate test acc: 1.0 loss: 0.20643699169158936\n","---intermediate test acc: 1.0 loss: 0.18014287948608398\n","---intermediate test acc: 1.0 loss: 0.12718826532363892\n","---intermediate test acc: 1.0 loss: 0.09186184406280518\n","---intermediate test acc: 1.0 loss: 0.525010883808136\n","---intermediate test acc: 1.0 loss: 0.47733891010284424\n","---intermediate test acc: 1.0 loss: 0.13062584400177002\n","---intermediate test acc: 1.0 loss: 0.27664715051651\n","---intermediate test acc: 1.0 loss: 0.4392607510089874\n","---intermediate test acc: 1.0 loss: 0.16450095176696777\n","---intermediate test acc: 1.0 loss: 0.10470831394195557\n","---intermediate test acc: 1.0 loss: 0.33694422245025635\n","---intermediate test acc: 1.0 loss: 0.05342972278594971\n","---intermediate test acc: 1.0 loss: 0.40344303846359253\n","---intermediate test acc: 1.0 loss: 0.1386549472808838\n","---intermediate test acc: 1.0 loss: 0.46107006072998047\n","---intermediate test acc: 1.0 loss: 0.29404348134994507\n","---intermediate test acc: 1.0 loss: 0.09977316856384277\n","---intermediate test acc: 1.0 loss: 0.3592280447483063\n","---intermediate test acc: 1.0 loss: 0.2966662645339966\n","---intermediate test acc: 1.0 loss: 0.18396157026290894\n","---intermediate test acc: 1.0 loss: 0.36004194617271423\n","---intermediate test acc: 1.0 loss: 0.22837769985198975\n","---intermediate test acc: 1.0 loss: 0.4034067392349243\n","---intermediate test acc: 1.0 loss: 0.22781509160995483\n","---intermediate test acc: 1.0 loss: 0.45391878485679626\n","---intermediate test acc: 1.0 loss: 0.3806264400482178\n","---intermediate test acc: 1.0 loss: 0.09098052978515625\n","---intermediate test acc: 1.0 loss: 0.48329561948776245\n","---intermediate test acc: 1.0 loss: 0.09486520290374756\n","---intermediate test acc: 1.0 loss: 0.22330832481384277\n","---intermediate test acc: 1.0 loss: 0.6159704923629761\n","---intermediate test acc: 1.0 loss: 0.2465888261795044\n","---intermediate test acc: 1.0 loss: 0.27830255031585693\n","---intermediate test acc: 1.0 loss: 0.21003878116607666\n","---intermediate test acc: 1.0 loss: 0.07927346229553223\n","---intermediate test acc: 1.0 loss: 0.1055138111114502\n","---intermediate test acc: 1.0 loss: 0.2610417604446411\n","---intermediate test acc: 1.0 loss: 0.3618939220905304\n","---intermediate test acc: 1.0 loss: 0.18680548667907715\n","---intermediate test acc: 0.0 loss: 0.7879656553268433\n","---intermediate test acc: 1.0 loss: 0.16137170791625977\n","---intermediate test acc: 1.0 loss: 0.260032594203949\n","---intermediate test acc: 1.0 loss: 0.3372957408428192\n","---intermediate test acc: 1.0 loss: 0.10327506065368652\n","---intermediate test acc: 1.0 loss: 0.11573755741119385\n","---intermediate test acc: 1.0 loss: 0.18238002061843872\n","---intermediate test acc: 1.0 loss: 0.2640293836593628\n","---intermediate test acc: 1.0 loss: 0.2010933756828308\n","---intermediate test acc: 1.0 loss: 0.16338229179382324\n","---intermediate test acc: 1.0 loss: 0.29864203929901123\n","---intermediate test acc: 1.0 loss: 0.28653210401535034\n","---intermediate test acc: 1.0 loss: 0.5657678842544556\n","---intermediate test acc: 1.0 loss: 0.3886178433895111\n","---intermediate test acc: 1.0 loss: 0.10893476009368896\n","---intermediate test acc: 1.0 loss: 0.2978934049606323\n","---intermediate test acc: 1.0 loss: 0.2948211431503296\n","---intermediate test acc: 1.0 loss: 0.10561680793762207\n","---intermediate test acc: 1.0 loss: 0.26172423362731934\n","---intermediate test acc: 1.0 loss: 0.18716216087341309\n","---intermediate test acc: 1.0 loss: 0.28822511434555054\n","---intermediate test acc: 1.0 loss: 0.24770766496658325\n","---intermediate test acc: 1.0 loss: 0.3933911621570587\n","---intermediate test acc: 1.0 loss: 0.08593320846557617\n","---intermediate test acc: 1.0 loss: 0.33594727516174316\n","---intermediate test acc: 1.0 loss: 0.3091406226158142\n","---intermediate test acc: 1.0 loss: 0.4065132439136505\n","---intermediate test acc: 1.0 loss: 0.389164000749588\n","---intermediate test acc: 1.0 loss: 0.29051655530929565\n","---intermediate test acc: 1.0 loss: 0.2322731614112854\n","---intermediate test acc: 1.0 loss: 0.22712039947509766\n","---intermediate test acc: 1.0 loss: 0.3149523138999939\n","---intermediate test acc: 1.0 loss: 0.12229669094085693\n","---intermediate test acc: 1.0 loss: 0.3133905231952667\n","---intermediate test acc: 1.0 loss: 0.20342117547988892\n","---intermediate test acc: 1.0 loss: 0.08811688423156738\n","---intermediate test acc: 1.0 loss: 0.23013031482696533\n","---intermediate test acc: 1.0 loss: 0.17959195375442505\n","---intermediate test acc: 1.0 loss: 0.2182961106300354\n","---intermediate test acc: 1.0 loss: 0.11980152130126953\n","---intermediate test acc: 1.0 loss: 0.0577850341796875\n","---intermediate test acc: 1.0 loss: 0.1466236114501953\n","---intermediate test acc: 1.0 loss: 0.1467524766921997\n","---intermediate test acc: 1.0 loss: 0.13018137216567993\n","---intermediate test acc: 1.0 loss: 0.3798985183238983\n","---intermediate test acc: 1.0 loss: 0.5329878330230713\n","---intermediate test acc: 1.0 loss: 0.46775585412979126\n","---intermediate test acc: 1.0 loss: 0.10973572731018066\n","---intermediate test acc: 1.0 loss: 0.49789851903915405\n","---intermediate test acc: 1.0 loss: 0.17737126350402832\n","---intermediate test acc: 1.0 loss: 0.54274582862854\n","---intermediate test acc: 1.0 loss: 0.3228272497653961\n","---intermediate test acc: 1.0 loss: 0.22977513074874878\n","---intermediate test acc: 1.0 loss: 0.30570152401924133\n","---intermediate test acc: 1.0 loss: 0.27520042657852173\n","---intermediate test acc: 1.0 loss: 0.18664515018463135\n","---intermediate test acc: 1.0 loss: 0.4043980538845062\n","---intermediate test acc: 1.0 loss: 0.25157850980758667\n","---intermediate test acc: 1.0 loss: 0.23116564750671387\n","---intermediate test acc: 1.0 loss: 0.41803187131881714\n","---intermediate test acc: 1.0 loss: 0.2819100618362427\n","---intermediate test acc: 1.0 loss: 0.16915303468704224\n","---intermediate test acc: 1.0 loss: 0.3159151077270508\n","---intermediate test acc: 1.0 loss: 0.4275341331958771\n","---intermediate test acc: 1.0 loss: 0.07592380046844482\n","---intermediate test acc: 1.0 loss: 0.4393202066421509\n","---intermediate test acc: 1.0 loss: 0.18110394477844238\n","---intermediate test acc: 1.0 loss: 0.1437801718711853\n","---intermediate test acc: 1.0 loss: 0.28103458881378174\n","---intermediate test acc: 1.0 loss: 0.266968309879303\n","---intermediate test acc: 1.0 loss: 0.23928570747375488\n","---intermediate test acc: 1.0 loss: 0.4511632025241852\n","---intermediate test acc: 1.0 loss: 0.28609198331832886\n","---intermediate test acc: 1.0 loss: 0.2280389666557312\n","---intermediate test acc: 1.0 loss: 0.1540905237197876\n","---intermediate test acc: 1.0 loss: 0.5669772624969482\n","---intermediate test acc: 1.0 loss: 0.12719523906707764\n","---intermediate test acc: 1.0 loss: 0.38147392868995667\n","---intermediate test acc: 1.0 loss: 0.22472524642944336\n","---intermediate test acc: 1.0 loss: 0.4528907537460327\n","---intermediate test acc: 1.0 loss: 0.2755874991416931\n","---intermediate test acc: 1.0 loss: 0.1707313060760498\n","---intermediate test acc: 1.0 loss: 0.2088947892189026\n","---intermediate test acc: 1.0 loss: 0.24140042066574097\n","---intermediate test acc: 1.0 loss: 0.17495828866958618\n","---intermediate test acc: 1.0 loss: 0.16763049364089966\n","---intermediate test acc: 1.0 loss: 0.16210389137268066\n","---intermediate test acc: 1.0 loss: 0.19899851083755493\n","---intermediate test acc: 0.0 loss: 0.8459360003471375\n","---intermediate test acc: 1.0 loss: 0.3230540156364441\n","---intermediate test acc: 1.0 loss: 0.15693336725234985\n","---intermediate test acc: 0.0 loss: 0.8625239133834839\n","---intermediate test acc: 1.0 loss: 0.19677722454071045\n","---intermediate test acc: 1.0 loss: 0.4739132821559906\n","---intermediate test acc: 1.0 loss: 0.41620826721191406\n","---intermediate test acc: 1.0 loss: 0.4441932439804077\n","---intermediate test acc: 1.0 loss: 0.10849392414093018\n","---intermediate test acc: 1.0 loss: 0.34490886330604553\n","---intermediate test acc: 1.0 loss: 0.26600730419158936\n","---intermediate test acc: 1.0 loss: 0.14966481924057007\n","---intermediate test acc: 1.0 loss: 0.16533517837524414\n","---intermediate test acc: 1.0 loss: 0.16021376848220825\n","---intermediate test acc: 1.0 loss: 0.1683671474456787\n","---intermediate test acc: 1.0 loss: 0.0949627161026001\n","---intermediate test acc: 1.0 loss: 0.11594319343566895\n","---intermediate test acc: 1.0 loss: 0.2743309736251831\n","---intermediate test acc: 0.0 loss: 0.8665643930435181\n","---intermediate test acc: 1.0 loss: 0.1975996494293213\n","---intermediate test acc: 1.0 loss: 0.4748286008834839\n","---intermediate test acc: 1.0 loss: 0.0616072416305542\n","---intermediate test acc: 1.0 loss: 0.13114655017852783\n","---intermediate test acc: 1.0 loss: 0.17788565158843994\n","---intermediate test acc: 1.0 loss: 0.16715651750564575\n","---intermediate test acc: 1.0 loss: 0.07743215560913086\n","---intermediate test acc: 1.0 loss: 0.2737243175506592\n","---intermediate test acc: 1.0 loss: 0.19166278839111328\n","---intermediate test acc: 1.0 loss: 0.18402338027954102\n","---intermediate test acc: 1.0 loss: 0.3569504916667938\n","---intermediate test acc: 1.0 loss: 0.1768849492073059\n","---intermediate test acc: 1.0 loss: 0.09322559833526611\n","---intermediate test acc: 1.0 loss: 0.2882002592086792\n","---intermediate test acc: 1.0 loss: 0.31617471575737\n","---intermediate test acc: 1.0 loss: 0.07856941223144531\n","---intermediate test acc: 1.0 loss: 0.38472461700439453\n","---intermediate test acc: 0.0 loss: 0.7863366603851318\n","---intermediate test acc: 1.0 loss: 0.1262727975845337\n","---intermediate test acc: 1.0 loss: 0.1535448431968689\n","---intermediate test acc: 1.0 loss: 0.23358792066574097\n","---intermediate test acc: 1.0 loss: 0.11679279804229736\n","---intermediate test acc: 1.0 loss: 0.3364264965057373\n","---intermediate test acc: 1.0 loss: 0.6382780075073242\n","---intermediate test acc: 1.0 loss: 0.5775386095046997\n","---intermediate test acc: 1.0 loss: 0.14346718788146973\n","---intermediate test acc: 1.0 loss: 0.15095621347427368\n","---intermediate test acc: 1.0 loss: 0.3869345188140869\n","---intermediate test acc: 1.0 loss: 0.4717951714992523\n","---intermediate test acc: 1.0 loss: 0.4469737112522125\n","---intermediate test acc: 1.0 loss: 0.5899335145950317\n","---intermediate test acc: 1.0 loss: 0.3530200123786926\n","---intermediate test acc: 1.0 loss: 0.1465885043144226\n","---intermediate test acc: 1.0 loss: 0.14794212579727173\n","---intermediate test acc: 1.0 loss: 0.39330217242240906\n","---intermediate test acc: 1.0 loss: 0.16266542673110962\n","---intermediate test acc: 1.0 loss: 0.121543288230896\n","---intermediate test acc: 1.0 loss: 0.4772956371307373\n","---intermediate test acc: 1.0 loss: 0.4164153039455414\n","---intermediate test acc: 1.0 loss: 0.0952378511428833\n","---intermediate test acc: 1.0 loss: 0.2812091112136841\n","---intermediate test acc: 1.0 loss: 0.16755998134613037\n","---intermediate test acc: 1.0 loss: 0.5307056903839111\n","---intermediate test acc: 1.0 loss: 0.3008902072906494\n","---intermediate test acc: 1.0 loss: 0.2412647008895874\n","---intermediate test acc: 1.0 loss: 0.19512158632278442\n","---intermediate test acc: 1.0 loss: 0.1300978660583496\n","---intermediate test acc: 1.0 loss: 0.13526713848114014\n","---intermediate test acc: 1.0 loss: 0.25392282009124756\n","---intermediate test acc: 1.0 loss: 0.10936164855957031\n","---intermediate test acc: 1.0 loss: 0.6288063526153564\n","---intermediate test acc: 1.0 loss: 0.09464633464813232\n","---intermediate test acc: 1.0 loss: 0.06795883178710938\n","---intermediate test acc: 1.0 loss: 0.11069905757904053\n","---intermediate test acc: 1.0 loss: 0.45491263270378113\n","---intermediate test acc: 1.0 loss: 0.4653697609901428\n","---intermediate test acc: 1.0 loss: 0.2056981325149536\n","---intermediate test acc: 1.0 loss: 0.061316728591918945\n","---intermediate test acc: 1.0 loss: 0.4451247751712799\n","---intermediate test acc: 1.0 loss: 0.38974520564079285\n","---intermediate test acc: 1.0 loss: 0.2673158049583435\n","---intermediate test acc: 1.0 loss: 0.10738956928253174\n","---intermediate test acc: 1.0 loss: 0.42284929752349854\n","---intermediate test acc: 1.0 loss: 0.671410858631134\n","---intermediate test acc: 1.0 loss: 0.34024733304977417\n","---intermediate test acc: 1.0 loss: 0.10439980030059814\n","---intermediate test acc: 1.0 loss: 0.6182184219360352\n","---intermediate test acc: 1.0 loss: 0.18470031023025513\n","---intermediate test acc: 1.0 loss: 0.14115387201309204\n","---intermediate test acc: 1.0 loss: 0.2128719687461853\n","---intermediate test acc: 0.0 loss: 0.8788325786590576\n","---intermediate test acc: 1.0 loss: 0.1748104691505432\n","---intermediate test acc: 1.0 loss: 0.10515213012695312\n","---intermediate test acc: 1.0 loss: 0.31906449794769287\n","---intermediate test acc: 1.0 loss: 0.23702895641326904\n","---intermediate test acc: 1.0 loss: 0.27075982093811035\n","---intermediate test acc: 1.0 loss: 0.45602118968963623\n","---intermediate test acc: 1.0 loss: 0.06834149360656738\n","---intermediate test acc: 1.0 loss: 0.38816526532173157\n","---intermediate test acc: 1.0 loss: 0.22413766384124756\n","---intermediate test acc: 1.0 loss: 0.30651649832725525\n","---intermediate test acc: 1.0 loss: 0.2267422080039978\n","---intermediate test acc: 0.0 loss: 0.7079866528511047\n","---intermediate test acc: 1.0 loss: 0.2209184169769287\n","---intermediate test acc: 1.0 loss: 0.4323863387107849\n","---intermediate test acc: 1.0 loss: 0.3497900366783142\n","---intermediate test acc: 1.0 loss: 0.3329227864742279\n","---intermediate test acc: 1.0 loss: 0.43385934829711914\n","---intermediate test acc: 1.0 loss: 0.520911455154419\n","---intermediate test acc: 1.0 loss: 0.07645559310913086\n","---intermediate test acc: 1.0 loss: 0.17712533473968506\n","---intermediate test acc: 1.0 loss: 0.17326873540878296\n","---intermediate test acc: 1.0 loss: 0.17198383808135986\n","---intermediate test acc: 1.0 loss: 0.1451079249382019\n","---intermediate test acc: 1.0 loss: 0.38263654708862305\n","---intermediate test acc: 0.0 loss: 1.1244137287139893\n","---intermediate test acc: 1.0 loss: 0.3969157338142395\n","---intermediate test acc: 1.0 loss: 0.21177178621292114\n","---intermediate test acc: 1.0 loss: 0.13273942470550537\n","---intermediate test acc: 1.0 loss: 0.19681185483932495\n","---intermediate test acc: 1.0 loss: 0.33195021748542786\n","---intermediate test acc: 1.0 loss: 0.27156001329421997\n","---intermediate test acc: 1.0 loss: 0.49210962653160095\n","---intermediate test acc: 1.0 loss: 0.23382562398910522\n","---intermediate test acc: 0.0 loss: 1.059853196144104\n","---intermediate test acc: 0.0 loss: 1.322800636291504\n","---intermediate test acc: 1.0 loss: 0.47816693782806396\n","---intermediate test acc: 1.0 loss: 0.19572633504867554\n","---intermediate test acc: 1.0 loss: 0.18009549379348755\n","---intermediate test acc: 1.0 loss: 0.1757444143295288\n","---intermediate test acc: 1.0 loss: 0.08214259147644043\n","---intermediate test acc: 1.0 loss: 0.22332072257995605\n","---intermediate test acc: 1.0 loss: 0.3705969452857971\n","---intermediate test acc: 1.0 loss: 0.29014360904693604\n","---intermediate test acc: 1.0 loss: 0.06552040576934814\n","---intermediate test acc: 1.0 loss: 0.41323021054267883\n","---intermediate test acc: 1.0 loss: 0.07732117176055908\n","---intermediate test acc: 1.0 loss: 0.3172137439250946\n","---intermediate test acc: 1.0 loss: 0.16524642705917358\n","---intermediate test acc: 1.0 loss: 0.40902867913246155\n","---intermediate test acc: 1.0 loss: 0.3608452081680298\n","---intermediate test acc: 1.0 loss: 0.3681100904941559\n","---intermediate test acc: 1.0 loss: 0.39029455184936523\n","---intermediate test acc: 1.0 loss: 0.34250113368034363\n","---intermediate test acc: 1.0 loss: 0.2349153757095337\n","---intermediate test acc: 1.0 loss: 0.44597968459129333\n","---intermediate test acc: 1.0 loss: 0.17019212245941162\n","---intermediate test acc: 1.0 loss: 0.47333258390426636\n","---intermediate test acc: 1.0 loss: 0.08352553844451904\n","---intermediate test acc: 1.0 loss: 0.2917042374610901\n","---intermediate test acc: 1.0 loss: 0.1457531452178955\n","---intermediate test acc: 1.0 loss: 0.08072984218597412\n","---intermediate test acc: 1.0 loss: 0.19325339794158936\n","---intermediate test acc: 1.0 loss: 0.3443889319896698\n","---intermediate test acc: 1.0 loss: 0.1659778356552124\n","---intermediate test acc: 1.0 loss: 0.1985730528831482\n","---intermediate test acc: 1.0 loss: 0.09868347644805908\n","---intermediate test acc: 1.0 loss: 0.33721834421157837\n","---intermediate test acc: 1.0 loss: 0.5154590606689453\n","---intermediate test acc: 1.0 loss: 0.23333418369293213\n","---intermediate test acc: 1.0 loss: 0.2684313654899597\n","---intermediate test acc: 1.0 loss: 0.18562251329421997\n","---intermediate test acc: 1.0 loss: 0.44566020369529724\n","---intermediate test acc: 1.0 loss: 0.136135995388031\n","---intermediate test acc: 1.0 loss: 0.1324748396873474\n","---intermediate test acc: 1.0 loss: 0.46993380784988403\n","---intermediate test acc: 1.0 loss: 0.37605512142181396\n","---intermediate test acc: 1.0 loss: 0.17241567373275757\n","---intermediate test acc: 1.0 loss: 0.16973042488098145\n","---intermediate test acc: 1.0 loss: 0.5399358868598938\n","---intermediate test acc: 1.0 loss: 0.1719428300857544\n","---intermediate test acc: 1.0 loss: 0.16450029611587524\n","---intermediate test acc: 1.0 loss: 0.2154078483581543\n","---intermediate test acc: 1.0 loss: 0.21113431453704834\n","---intermediate test acc: 1.0 loss: 0.2632538676261902\n","---intermediate test acc: 1.0 loss: 0.17614668607711792\n","---intermediate test acc: 1.0 loss: 0.20369338989257812\n","---intermediate test acc: 1.0 loss: 0.25137144327163696\n","---intermediate test acc: 1.0 loss: 0.12118732929229736\n","---intermediate test acc: 1.0 loss: 0.07736992835998535\n","---intermediate test acc: 1.0 loss: 0.13471436500549316\n","---intermediate test acc: 1.0 loss: 0.1719672679901123\n","---intermediate test acc: 1.0 loss: 0.11395668983459473\n","---intermediate test acc: 1.0 loss: 0.3284754455089569\n","---intermediate test acc: 1.0 loss: 0.19534093141555786\n","---intermediate test acc: 1.0 loss: 0.05746114253997803\n","---intermediate test acc: 1.0 loss: 0.12556374073028564\n","---intermediate test acc: 1.0 loss: 0.5186858177185059\n","---intermediate test acc: 1.0 loss: 0.6251635551452637\n","---intermediate test acc: 1.0 loss: 0.06663799285888672\n","---intermediate test acc: 1.0 loss: 0.46775585412979126\n","---intermediate test acc: 1.0 loss: 0.2568289637565613\n","---intermediate test acc: 0.0 loss: 0.7322474122047424\n","---intermediate test acc: 1.0 loss: 0.321924090385437\n","---intermediate test acc: 0.0 loss: 0.934185266494751\n","---intermediate test acc: 1.0 loss: 0.05931651592254639\n","---intermediate test acc: 1.0 loss: 0.6226201057434082\n","---intermediate test acc: 1.0 loss: 0.11704635620117188\n","---intermediate test acc: 1.0 loss: 0.11573529243469238\n","---intermediate test acc: 1.0 loss: 0.18684548139572144\n","---intermediate test acc: 1.0 loss: 0.388816237449646\n","---intermediate test acc: 1.0 loss: 0.23606693744659424\n","---intermediate test acc: 1.0 loss: 0.2411125898361206\n","---intermediate test acc: 1.0 loss: 0.3743543028831482\n","---intermediate test acc: 1.0 loss: 0.26709938049316406\n","---intermediate test acc: 1.0 loss: 0.1516857147216797\n","---intermediate test acc: 1.0 loss: 0.5942099690437317\n","---intermediate test acc: 1.0 loss: 0.2920936942100525\n","---intermediate test acc: 1.0 loss: 0.2985374629497528\n","---intermediate test acc: 1.0 loss: 0.1887792944908142\n","---intermediate test acc: 1.0 loss: 0.30101025104522705\n","---intermediate test acc: 1.0 loss: 0.1574433445930481\n","---intermediate test acc: 1.0 loss: 0.19004559516906738\n","---intermediate test acc: 1.0 loss: 0.09881329536437988\n","---intermediate test acc: 1.0 loss: 0.23313331604003906\n","---intermediate test acc: 1.0 loss: 0.1852913498878479\n","---intermediate test acc: 1.0 loss: 0.07892799377441406\n","---intermediate test acc: 1.0 loss: 0.054990530014038086\n","---intermediate test acc: 1.0 loss: 0.5559368133544922\n","---intermediate test acc: 1.0 loss: 0.23843228816986084\n","---intermediate test acc: 1.0 loss: 0.13261938095092773\n","---intermediate test acc: 1.0 loss: 0.3493230938911438\n","---intermediate test acc: 1.0 loss: 0.6047123074531555\n","---intermediate test acc: 1.0 loss: 0.2832828164100647\n","---intermediate test acc: 1.0 loss: 0.5693703889846802\n","---intermediate test acc: 1.0 loss: 0.46090614795684814\n","---intermediate test acc: 1.0 loss: 0.47031447291374207\n","---intermediate test acc: 1.0 loss: 0.22334039211273193\n","---intermediate test acc: 1.0 loss: 0.25662684440612793\n","---intermediate test acc: 1.0 loss: 0.17045456171035767\n","---intermediate test acc: 1.0 loss: 0.13023042678833008\n","---intermediate test acc: 1.0 loss: 0.15373390913009644\n","---intermediate test acc: 0.0 loss: 0.9671481251716614\n","---intermediate test acc: 1.0 loss: 0.3542420268058777\n","---intermediate test acc: 1.0 loss: 0.520524263381958\n","---intermediate test acc: 1.0 loss: 0.27480369806289673\n","---intermediate test acc: 1.0 loss: 0.2764822840690613\n","---intermediate test acc: 1.0 loss: 0.16099834442138672\n","---intermediate test acc: 1.0 loss: 0.13591283559799194\n","---intermediate test acc: 1.0 loss: 0.2924254536628723\n","---intermediate test acc: 1.0 loss: 0.10745930671691895\n","---intermediate test acc: 1.0 loss: 0.5403764247894287\n","---intermediate test acc: 1.0 loss: 0.49844059348106384\n","---intermediate test acc: 1.0 loss: 0.3840298354625702\n","---intermediate test acc: 1.0 loss: 0.3668000102043152\n","---intermediate test acc: 1.0 loss: 0.2529318332672119\n","---intermediate test acc: 1.0 loss: 0.12406277656555176\n","---intermediate test acc: 1.0 loss: 0.43007543683052063\n","---intermediate test acc: 1.0 loss: 0.369663804769516\n","---intermediate test acc: 1.0 loss: 0.45714980363845825\n","---intermediate test acc: 1.0 loss: 0.156829833984375\n","---intermediate test acc: 1.0 loss: 0.10063672065734863\n","---intermediate test acc: 1.0 loss: 0.24326598644256592\n","---intermediate test acc: 1.0 loss: 0.27912437915802\n","---intermediate test acc: 1.0 loss: 0.4234541058540344\n","---intermediate test acc: 1.0 loss: 0.07537245750427246\n","---intermediate test acc: 1.0 loss: 0.10807979106903076\n","---intermediate test acc: 1.0 loss: 0.10565972328186035\n","---intermediate test acc: 1.0 loss: 0.3591093122959137\n","---intermediate test acc: 1.0 loss: 0.1832566261291504\n","---intermediate test acc: 1.0 loss: 0.14885056018829346\n","---intermediate test acc: 1.0 loss: 0.5672454237937927\n","---intermediate test acc: 1.0 loss: 0.13713514804840088\n","---intermediate test acc: 1.0 loss: 0.4070209264755249\n","---intermediate test acc: 1.0 loss: 0.3897501528263092\n","---intermediate test acc: 1.0 loss: 0.25713950395584106\n","---intermediate test acc: 1.0 loss: 0.4463930130004883\n","---intermediate test acc: 1.0 loss: 0.27273571491241455\n","---intermediate test acc: 1.0 loss: 0.1314917802810669\n","---intermediate test acc: 1.0 loss: 0.5355128049850464\n","---intermediate test acc: 1.0 loss: 0.24717682600021362\n","---intermediate test acc: 1.0 loss: 0.31258609890937805\n","---intermediate test acc: 1.0 loss: 0.19126588106155396\n","---intermediate test acc: 1.0 loss: 0.6165689826011658\n","---intermediate test acc: 1.0 loss: 0.23645013570785522\n","---intermediate test acc: 1.0 loss: 0.13065671920776367\n","---intermediate test acc: 1.0 loss: 0.1991492509841919\n","---intermediate test acc: 1.0 loss: 0.3176654875278473\n","---intermediate test acc: 1.0 loss: 0.39730486273765564\n","---intermediate test acc: 1.0 loss: 0.548061728477478\n","---intermediate test acc: 1.0 loss: 0.16978603601455688\n","---intermediate test acc: 1.0 loss: 0.17686593532562256\n","---intermediate test acc: 1.0 loss: 0.10957801342010498\n","---intermediate test acc: 1.0 loss: 0.31412965059280396\n","---intermediate test acc: 1.0 loss: 0.4667785167694092\n","---intermediate test acc: 1.0 loss: 0.29109883308410645\n","---intermediate test acc: 1.0 loss: 0.4982767701148987\n","---intermediate test acc: 1.0 loss: 0.18711382150650024\n","---intermediate test acc: 1.0 loss: 0.08287692070007324\n","---intermediate test acc: 1.0 loss: 0.268912672996521\n","---intermediate test acc: 1.0 loss: 0.12713754177093506\n","---intermediate test acc: 1.0 loss: 0.09140300750732422\n","---intermediate test acc: 1.0 loss: 0.23222601413726807\n","---intermediate test acc: 1.0 loss: 0.10698926448822021\n","---intermediate test acc: 1.0 loss: 0.36379316449165344\n","---intermediate test acc: 1.0 loss: 0.2531832456588745\n","---intermediate test acc: 1.0 loss: 0.1483103632926941\n","---intermediate test acc: 1.0 loss: 0.18633383512496948\n","---intermediate test acc: 1.0 loss: 0.14591681957244873\n","---intermediate test acc: 1.0 loss: 0.07039749622344971\n","---intermediate test acc: 1.0 loss: 0.5489810109138489\n","---intermediate test acc: 1.0 loss: 0.18796944618225098\n","---intermediate test acc: 1.0 loss: 0.5423940420150757\n","---intermediate test acc: 1.0 loss: 0.3648323118686676\n","---intermediate test acc: 1.0 loss: 0.22701752185821533\n","---intermediate test acc: 1.0 loss: 0.24960798025131226\n","---intermediate test acc: 1.0 loss: 0.23242521286010742\n","---intermediate test acc: 1.0 loss: 0.17888391017913818\n","---intermediate test acc: 1.0 loss: 0.36186885833740234\n","---intermediate test acc: 1.0 loss: 0.13350915908813477\n","---intermediate test acc: 1.0 loss: 0.47335246205329895\n","---intermediate test acc: 1.0 loss: 0.3537684679031372\n","---intermediate test acc: 1.0 loss: 0.37121617794036865\n","---intermediate test acc: 1.0 loss: 0.12626713514328003\n","---intermediate test acc: 1.0 loss: 0.39872652292251587\n","---intermediate test acc: 1.0 loss: 0.4854145050048828\n","---intermediate test acc: 1.0 loss: 0.32033243775367737\n","---intermediate test acc: 1.0 loss: 0.511188805103302\n","---intermediate test acc: 1.0 loss: 0.33577263355255127\n","---intermediate test acc: 1.0 loss: 0.18724054098129272\n","---intermediate test acc: 1.0 loss: 0.27582985162734985\n","---intermediate test acc: 1.0 loss: 0.2306104302406311\n","---intermediate test acc: 1.0 loss: 0.09977495670318604\n","---intermediate test acc: 1.0 loss: 0.42566996812820435\n","---intermediate test acc: 1.0 loss: 0.4225384593009949\n","---intermediate test acc: 1.0 loss: 0.3231251835823059\n","---intermediate test acc: 1.0 loss: 0.35359758138656616\n","---intermediate test acc: 1.0 loss: 0.11236107349395752\n","---intermediate test acc: 1.0 loss: 0.49423420429229736\n","---intermediate test acc: 1.0 loss: 0.3578956723213196\n","---intermediate test acc: 1.0 loss: 0.4481494128704071\n","---intermediate test acc: 1.0 loss: 0.09618842601776123\n","---intermediate test acc: 1.0 loss: 0.11287343502044678\n","---intermediate test acc: 1.0 loss: 0.32533952593803406\n","---intermediate test acc: 1.0 loss: 0.3465300500392914\n","---intermediate test acc: 1.0 loss: 0.15619415044784546\n","---intermediate test acc: 1.0 loss: 0.06623578071594238\n","---intermediate test acc: 1.0 loss: 0.1184467077255249\n","---intermediate test acc: 1.0 loss: 0.538926899433136\n","---intermediate test acc: 1.0 loss: 0.16587871313095093\n","---intermediate test acc: 1.0 loss: 0.45092257857322693\n","---intermediate test acc: 1.0 loss: 0.39224979281425476\n","---intermediate test acc: 0.0 loss: 0.7234422564506531\n","---intermediate test acc: 1.0 loss: 0.09679234027862549\n","---intermediate test acc: 1.0 loss: 0.414241760969162\n","---intermediate test acc: 1.0 loss: 0.07142996788024902\n","---intermediate test acc: 1.0 loss: 0.30941352248191833\n","---intermediate test acc: 1.0 loss: 0.15945035219192505\n","---intermediate test acc: 1.0 loss: 0.2458350658416748\n","---intermediate test acc: 1.0 loss: 0.29896077513694763\n","---intermediate test acc: 1.0 loss: 0.07068014144897461\n","---intermediate test acc: 1.0 loss: 0.35894155502319336\n","TEST: acc: 0.968937875751503 loss: 0.29305773973464966\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RAk1cVG9-2tm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"82dbcbaf-370b-4604-9d13-39834cba0ad9","executionInfo":{"status":"ok","timestamp":1575363774324,"user_tz":-60,"elapsed":219249,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}}},"source":["test_data_location = [\"/content/drive/My Drive/FaceForensics_Sequences/FaceForensics_Testset/original_sequences/youtube/c40/sequences_299x299_5seq@10frames_skip_5_uniform\",\n","                 \"/content/drive/My Drive/FaceForensics_Sequences/FaceForensics_Testset/manipulated_sequences/FaceSwap/c40/sequences_299x299_5seq@10frames_skip_5_uniform\"]\n","test_dataset = FaceForensicsImagesDataset(test_data_location, transform=ToTensor())\n","\n","test_indices = range(len(test_dataset))\n","\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, \n","                                           sampler=test_sampler)\n","\n","print(\"Length of test dataset: {}\".format(len(test_dataset)))\n","\n","from torch.autograd import Variable\n","model.eval()  # EVAL mode (for dropout, batchnorm, etc.)\n","with torch.no_grad():\n","    test_losses = []\n","    test_acc = []\n","    for sample in test_loader:\n","        xb = sample[\"image\"]\n","        yb = sample[\"label\"]\n","\n","        xb, yb = Variable(xb), Variable(yb)\n","        #if str(device) != 'cpu':\n","        xb, yb = xb.cuda(), yb.cuda()\n","\n","\n","        #xb, yb = wrap_data(xb, yb, device)\n","\n","        # FORWARD PASS --> Loss calculation\n","        loss_func = torch.nn.CrossEntropyLoss()\n","        scores = model(xb)\n","        loss = loss_func(scores, yb)\n","        loss = loss.data.cpu().numpy()\n","        test_losses.append(loss)\n","      \n","        _, preds = torch.max(scores, 1) # select highest value as the predicted class\n","        #y_mask = yb >= 0 # do not allow \"-1\" segmentation value\n","        acc = np.mean((preds == yb).data.cpu().numpy())  # check if prediction is correct + average of it for all N inputs\n","\n","        test_acc.append(acc)\n","\n","    test_loss = np.mean(test_losses)\n","    test_acc = np.mean(test_acc)\n","\n","    print(\"TEST: acc: {} loss: {}\".format(test_acc, test_loss))\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Length of test dataset: 998\n","TEST: acc: 0.5711422845691383 loss: 0.7208824157714844\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575361861204,"user_tz":-60,"elapsed":1384,"user":{"displayName":"Lukas Höllein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDwzCvAFnTfi5ricw5y8UtyqnO0qualNSbeeB563Jc=s64","userId":"06904665613904304406"}},"id":"FMS0DwtHAyBp","outputId":"0d94bc19-9633-4aa9-ed3b-c3313ac80ba4","colab":{"base_uri":"https://localhost:8080/","height":730}},"source":["# Run this cell to visualize training loss and train / val accuracy\n","\n","plt.subplot(3, 1, 1)\n","plt.title('Training loss')\n","plt.plot(solver.train_loss_history, 'o')\n","plt.xlabel('Iteration')\n","\n","plt.subplot(3, 1, 2)\n","plt.title('Validation loss')\n","plt.plot(solver.val_loss_history, 'o')\n","plt.xlabel('Iteration')\n","\n","plt.subplot(3, 1, 3)\n","plt.title('Accuracy')\n","plt.plot(solver.train_acc_history, '-o', label='train')\n","plt.plot(solver.val_acc_history, '-o', label='val')\n","plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n","plt.xlabel('Epoch')\n","plt.legend(loc='lower right')\n","plt.gcf().set_size_inches(15, 12)\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA3YAAALJCAYAAAD4RrGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAATNwn9MaMZe2eMNgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 1080x864 with 3 Axes>"]},"metadata":{"tags":[]}}]}]}